{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Copy of DS7_lesson_applied_modeling_2.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.1"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/erivetna87/DS-Unit-2-Applied-Modeling/blob/master/ER_DS7_lesson_applied_modeling_2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U2ha9OWxf0jw",
        "colab_type": "text"
      },
      "source": [
        "Lambda School Data Science\n",
        "\n",
        "*Unit 2, Sprint 3, Module 2*\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "-hTictxWYih7"
      },
      "source": [
        "# Applied Modeling, Module 2\n",
        "\n",
        "- Get **permutation importances** for model interpretation and feature selection\n",
        "- Use xgboost for **gradient boosting**\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "LoxNYFBXYih9"
      },
      "source": [
        "### Default Feature Importances are fast, but Permutation Importances may be more accurate\n",
        "\n",
        "- Permutation Importances\n",
        "  - [Kaggle / Dan Becker: Machine Learning Explainability](https://www.kaggle.com/dansbecker/permutation-importance)\n",
        "  - [Christoph Molnar: Interpretable Machine Learning](https://christophm.github.io/interpretable-ml-book/feature-importance.html)\n",
        "- (Default) Feature Importances\n",
        "  - [Ando Saabas: Selecting good features, Part 3, Random Forests](https://blog.datadive.net/selecting-good-features-part-iii-random-forests/)\n",
        "  - [Terence Parr, et al: Beware Default Random Forest Importances](https://explained.ai/rf-importance/index.html)\n",
        "\n",
        "### Try Tree Ensembles when you do machine learning with labeled, tabular data\n",
        "- \"Tree Ensembles\" means Random Forest or **Gradient Boosting** models. \n",
        "- [Tree Ensembles often have the best predictive accuracy](https://arxiv.org/abs/1708.05070) with labeled, tabular data.\n",
        "- Why? Because trees can fit non-linear, non-[monotonic](https://en.wikipedia.org/wiki/Monotonic_function) relationships, and [interactions](https://christophm.github.io/interpretable-ml-book/interaction.html) between features.\n",
        "- A single decision tree, grown to unlimited depth, will [overfit](http://www.r2d3.us/visual-intro-to-machine-learning-part-1/). We solve this problem by ensembling trees, with bagging (Random Forest) or **[boosting](https://www.youtube.com/watch?v=GM3CDQfQ4sw)** (Gradient Boosting).\n",
        "- Random Forest's advantage: may be less sensitive to hyperparameters. **Gradient Boosting's advantage:** may get better predictive accuracy.\n",
        "\n",
        "#### Python libraries for Gradient Boosting\n",
        "- [scikit-learn Gradient Tree Boosting](https://scikit-learn.org/stable/modules/ensemble.html#gradient-boosting) — slower than other libraries, but [the new version may be better](https://twitter.com/amuellerml/status/1129443826945396737)\n",
        "  - Anaconda: already installed\n",
        "  - Google Colab: already installed\n",
        "- [xgboost](https://xgboost.readthedocs.io/en/latest/) — can accept missing values and enforce [monotonic constraints](https://xiaoxiaowang87.github.io/monotonicity_constraint/)\n",
        "  - Anaconda, Mac/Linux: `conda install -c conda-forge xgboost`\n",
        "  - Windows: `conda install -c anaconda py-xgboost`\n",
        "  - Google Colab: already installed\n",
        "- [LightGBM](https://lightgbm.readthedocs.io/en/latest/) — can accept missing values and enforce [monotonic constraints](https://blog.datadive.net/monotonicity-constraints-in-machine-learning/)\n",
        "  - Anaconda: `conda install -c conda-forge lightgbm`\n",
        "  - Google Colab: already installed\n",
        "- [CatBoost](https://catboost.ai/) — can accept missing values and use [categorical features](https://catboost.ai/docs/concepts/algorithm-main-stages_cat-to-numberic.html) without preprocessing\n",
        "  - Anaconda: `conda install -c conda-forge catboost`\n",
        "  - Google Colab: `pip install catboost`"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wMejJg0w8v76",
        "colab_type": "text"
      },
      "source": [
        "### Setup\n",
        "\n",
        "You can work locally (follow the [local setup instructions](https://lambdaschool.github.io/ds/unit2/local/)) or on Colab (run the code cell below)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "BFQMky3CYih-",
        "outputId": "f5ac02c2-eb5d-4e66-f2e1-76e19af698d2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "import os, sys\n",
        "in_colab = 'google.colab' in sys.modules\n",
        "\n",
        "# If you're in Colab...\n",
        "if in_colab:\n",
        "    # Pull files from Github repo\n",
        "    os.chdir('/content')\n",
        "    !git init .\n",
        "    !git remote add origin https://github.com/LambdaSchool/DS-Unit-2-Applied-Modeling.git\n",
        "    !git pull origin master\n",
        "    \n",
        "    # Install required python packages\n",
        "    !pip install -r requirements.txt\n",
        "    \n",
        "    # Change into directory for module\n",
        "    os.chdir('module2')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Initialized empty Git repository in /content/.git/\n",
            "remote: Enumerating objects: 5, done.\u001b[K\n",
            "remote: Counting objects: 100% (5/5), done.\u001b[K\n",
            "remote: Compressing objects: 100% (5/5), done.\u001b[K\n",
            "remote: Total 68 (delta 0), reused 4 (delta 0), pack-reused 63\n",
            "Unpacking objects: 100% (68/68), done.\n",
            "From https://github.com/LambdaSchool/DS-Unit-2-Applied-Modeling\n",
            " * branch            master     -> FETCH_HEAD\n",
            " * [new branch]      master     -> origin/master\n",
            "Checking out files: 100% (27/27), done.\n",
            "Collecting category_encoders==2.0.0 (from -r requirements.txt (line 1))\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/6e/a1/f7a22f144f33be78afeb06bfa78478e8284a64263a3c09b1ef54e673841e/category_encoders-2.0.0-py2.py3-none-any.whl (87kB)\n",
            "\u001b[K     |████████████████████████████████| 92kB 5.0MB/s \n",
            "\u001b[?25hCollecting eli5==0.10.1 (from -r requirements.txt (line 2))\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/97/2f/c85c7d8f8548e460829971785347e14e45fa5c6617da374711dec8cb38cc/eli5-0.10.1-py2.py3-none-any.whl (105kB)\n",
            "\u001b[K     |████████████████████████████████| 112kB 7.7MB/s \n",
            "\u001b[?25hRequirement already satisfied: matplotlib!=3.1.1 in /usr/local/lib/python3.6/dist-packages (from -r requirements.txt (line 3)) (3.0.3)\n",
            "Collecting pandas-profiling==2.3.0 (from -r requirements.txt (line 4))\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/2c/2f/aae19e2173c10a9bb7fee5f5cad35dbe53a393960fc91abc477dcc4661e8/pandas-profiling-2.3.0.tar.gz (127kB)\n",
            "\u001b[K     |████████████████████████████████| 133kB 46.1MB/s \n",
            "\u001b[?25hCollecting pdpbox==0.2.0 (from -r requirements.txt (line 5))\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/87/23/ac7da5ba1c6c03a87c412e7e7b6e91a10d6ecf4474906c3e736f93940d49/PDPbox-0.2.0.tar.gz (57.7MB)\n",
            "\u001b[K     |████████████████████████████████| 57.7MB 40.5MB/s \n",
            "\u001b[?25hRequirement already satisfied: plotly==4.1.1 in /usr/local/lib/python3.6/dist-packages (from -r requirements.txt (line 6)) (4.1.1)\n",
            "Requirement already satisfied: seaborn==0.9.0 in /usr/local/lib/python3.6/dist-packages (from -r requirements.txt (line 7)) (0.9.0)\n",
            "Requirement already satisfied: scikit-learn==0.21.3 in /usr/local/lib/python3.6/dist-packages (from -r requirements.txt (line 8)) (0.21.3)\n",
            "Collecting shap==0.30.0 (from -r requirements.txt (line 9))\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/3b/98/16829410426bdd08b836c30e164c56646d6a102afb9eadd81a6bd3a8bb65/shap-0.30.0.tar.gz (240kB)\n",
            "\u001b[K     |████████████████████████████████| 245kB 33.9MB/s \n",
            "\u001b[?25hRequirement already satisfied: xgboost==0.90 in /usr/local/lib/python3.6/dist-packages (from -r requirements.txt (line 10)) (0.90)\n",
            "Requirement already satisfied: numpy>=1.11.3 in /usr/local/lib/python3.6/dist-packages (from category_encoders==2.0.0->-r requirements.txt (line 1)) (1.16.5)\n",
            "Requirement already satisfied: statsmodels>=0.6.1 in /usr/local/lib/python3.6/dist-packages (from category_encoders==2.0.0->-r requirements.txt (line 1)) (0.10.1)\n",
            "Requirement already satisfied: patsy>=0.4.1 in /usr/local/lib/python3.6/dist-packages (from category_encoders==2.0.0->-r requirements.txt (line 1)) (0.5.1)\n",
            "Requirement already satisfied: scipy>=0.19.0 in /usr/local/lib/python3.6/dist-packages (from category_encoders==2.0.0->-r requirements.txt (line 1)) (1.3.1)\n",
            "Requirement already satisfied: pandas>=0.21.1 in /usr/local/lib/python3.6/dist-packages (from category_encoders==2.0.0->-r requirements.txt (line 1)) (0.24.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.6/dist-packages (from eli5==0.10.1->-r requirements.txt (line 2)) (2.10.1)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from eli5==0.10.1->-r requirements.txt (line 2)) (1.12.0)\n",
            "Requirement already satisfied: graphviz in /usr/local/lib/python3.6/dist-packages (from eli5==0.10.1->-r requirements.txt (line 2)) (0.10.1)\n",
            "Requirement already satisfied: attrs>16.0.0 in /usr/local/lib/python3.6/dist-packages (from eli5==0.10.1->-r requirements.txt (line 2)) (19.1.0)\n",
            "Requirement already satisfied: tabulate>=0.7.7 in /usr/local/lib/python3.6/dist-packages (from eli5==0.10.1->-r requirements.txt (line 2)) (0.8.3)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.6/dist-packages (from matplotlib!=3.1.1->-r requirements.txt (line 3)) (0.10.0)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib!=3.1.1->-r requirements.txt (line 3)) (2.4.2)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib!=3.1.1->-r requirements.txt (line 3)) (2.5.3)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib!=3.1.1->-r requirements.txt (line 3)) (1.1.0)\n",
            "Requirement already satisfied: missingno>=0.4.2 in /usr/local/lib/python3.6/dist-packages (from pandas-profiling==2.3.0->-r requirements.txt (line 4)) (0.4.2)\n",
            "Collecting htmlmin>=0.1.12 (from pandas-profiling==2.3.0->-r requirements.txt (line 4))\n",
            "  Downloading https://files.pythonhosted.org/packages/b3/e7/fcd59e12169de19f0131ff2812077f964c6b960e7c09804d30a7bf2ab461/htmlmin-0.1.12.tar.gz\n",
            "Collecting phik>=0.9.8 (from pandas-profiling==2.3.0->-r requirements.txt (line 4))\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/45/ad/24a16fa4ba612fb96a3c4bb115a5b9741483f53b66d3d3afd987f20fa227/phik-0.9.8-py3-none-any.whl (606kB)\n",
            "\u001b[K     |████████████████████████████████| 614kB 37.1MB/s \n",
            "\u001b[?25hCollecting confuse>=1.0.0 (from pandas-profiling==2.3.0->-r requirements.txt (line 4))\n",
            "  Downloading https://files.pythonhosted.org/packages/4c/6f/90e860cba937c174d8b3775729ccc6377eb91f52ad4eeb008e7252a3646d/confuse-1.0.0.tar.gz\n",
            "Requirement already satisfied: astropy in /usr/local/lib/python3.6/dist-packages (from pandas-profiling==2.3.0->-r requirements.txt (line 4)) (3.0.5)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.6/dist-packages (from pdpbox==0.2.0->-r requirements.txt (line 5)) (0.13.2)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.6/dist-packages (from pdpbox==0.2.0->-r requirements.txt (line 5)) (5.4.8)\n",
            "Requirement already satisfied: retrying>=1.3.3 in /usr/local/lib/python3.6/dist-packages (from plotly==4.1.1->-r requirements.txt (line 6)) (1.3.3)\n",
            "Requirement already satisfied: tqdm>4.25.0 in /usr/local/lib/python3.6/dist-packages (from shap==0.30.0->-r requirements.txt (line 9)) (4.28.1)\n",
            "Requirement already satisfied: ipython in /usr/local/lib/python3.6/dist-packages (from shap==0.30.0->-r requirements.txt (line 9)) (5.5.0)\n",
            "Requirement already satisfied: scikit-image in /usr/local/lib/python3.6/dist-packages (from shap==0.30.0->-r requirements.txt (line 9)) (0.15.0)\n",
            "Requirement already satisfied: pytz>=2011k in /usr/local/lib/python3.6/dist-packages (from pandas>=0.21.1->category_encoders==2.0.0->-r requirements.txt (line 1)) (2018.9)\n",
            "Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.6/dist-packages (from jinja2->eli5==0.10.1->-r requirements.txt (line 2)) (1.1.1)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from kiwisolver>=1.0.1->matplotlib!=3.1.1->-r requirements.txt (line 3)) (41.2.0)\n",
            "Requirement already satisfied: numba>=0.38.1 in /usr/local/lib/python3.6/dist-packages (from phik>=0.9.8->pandas-profiling==2.3.0->-r requirements.txt (line 4)) (0.40.1)\n",
            "Requirement already satisfied: nbconvert>=5.3.1 in /usr/local/lib/python3.6/dist-packages (from phik>=0.9.8->pandas-profiling==2.3.0->-r requirements.txt (line 4)) (5.6.0)\n",
            "Requirement already satisfied: jupyter-client>=5.2.3 in /usr/local/lib/python3.6/dist-packages (from phik>=0.9.8->pandas-profiling==2.3.0->-r requirements.txt (line 4)) (5.3.1)\n",
            "Collecting pytest>=4.0.2 (from phik>=0.9.8->pandas-profiling==2.3.0->-r requirements.txt (line 4))\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/2f/19/d5f71752f71451ccc5ed5f6739e9da4a235f38783fdaf3629cae41b2ca7b/pytest-5.1.2-py3-none-any.whl (224kB)\n",
            "\u001b[K     |████████████████████████████████| 225kB 44.4MB/s \n",
            "\u001b[?25hCollecting pytest-pylint>=0.13.0 (from phik>=0.9.8->pandas-profiling==2.3.0->-r requirements.txt (line 4))\n",
            "  Downloading https://files.pythonhosted.org/packages/64/dc/6f35f114844fb12e38d60c4f3d2441a55baff7043ad4e013777dff55746c/pytest_pylint-0.14.1-py3-none-any.whl\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.6/dist-packages (from confuse>=1.0.0->pandas-profiling==2.3.0->-r requirements.txt (line 4)) (3.13)\n",
            "Requirement already satisfied: pickleshare in /usr/local/lib/python3.6/dist-packages (from ipython->shap==0.30.0->-r requirements.txt (line 9)) (0.7.5)\n",
            "Requirement already satisfied: decorator in /usr/local/lib/python3.6/dist-packages (from ipython->shap==0.30.0->-r requirements.txt (line 9)) (4.4.0)\n",
            "Requirement already satisfied: traitlets>=4.2 in /usr/local/lib/python3.6/dist-packages (from ipython->shap==0.30.0->-r requirements.txt (line 9)) (4.3.2)\n",
            "Requirement already satisfied: pexpect; sys_platform != \"win32\" in /usr/local/lib/python3.6/dist-packages (from ipython->shap==0.30.0->-r requirements.txt (line 9)) (4.7.0)\n",
            "Requirement already satisfied: simplegeneric>0.8 in /usr/local/lib/python3.6/dist-packages (from ipython->shap==0.30.0->-r requirements.txt (line 9)) (0.8.1)\n",
            "Requirement already satisfied: prompt-toolkit<2.0.0,>=1.0.4 in /usr/local/lib/python3.6/dist-packages (from ipython->shap==0.30.0->-r requirements.txt (line 9)) (1.0.16)\n",
            "Requirement already satisfied: pygments in /usr/local/lib/python3.6/dist-packages (from ipython->shap==0.30.0->-r requirements.txt (line 9)) (2.1.3)\n",
            "Requirement already satisfied: PyWavelets>=0.4.0 in /usr/local/lib/python3.6/dist-packages (from scikit-image->shap==0.30.0->-r requirements.txt (line 9)) (1.0.3)\n",
            "Requirement already satisfied: networkx>=2.0 in /usr/local/lib/python3.6/dist-packages (from scikit-image->shap==0.30.0->-r requirements.txt (line 9)) (2.3)\n",
            "Requirement already satisfied: imageio>=2.0.1 in /usr/local/lib/python3.6/dist-packages (from scikit-image->shap==0.30.0->-r requirements.txt (line 9)) (2.4.1)\n",
            "Requirement already satisfied: pillow>=4.3.0 in /usr/local/lib/python3.6/dist-packages (from scikit-image->shap==0.30.0->-r requirements.txt (line 9)) (4.3.0)\n",
            "Requirement already satisfied: llvmlite>=0.25.0dev0 in /usr/local/lib/python3.6/dist-packages (from numba>=0.38.1->phik>=0.9.8->pandas-profiling==2.3.0->-r requirements.txt (line 4)) (0.29.0)\n",
            "Requirement already satisfied: bleach in /usr/local/lib/python3.6/dist-packages (from nbconvert>=5.3.1->phik>=0.9.8->pandas-profiling==2.3.0->-r requirements.txt (line 4)) (3.1.0)\n",
            "Requirement already satisfied: pandocfilters>=1.4.1 in /usr/local/lib/python3.6/dist-packages (from nbconvert>=5.3.1->phik>=0.9.8->pandas-profiling==2.3.0->-r requirements.txt (line 4)) (1.4.2)\n",
            "Requirement already satisfied: mistune<2,>=0.8.1 in /usr/local/lib/python3.6/dist-packages (from nbconvert>=5.3.1->phik>=0.9.8->pandas-profiling==2.3.0->-r requirements.txt (line 4)) (0.8.4)\n",
            "Requirement already satisfied: entrypoints>=0.2.2 in /usr/local/lib/python3.6/dist-packages (from nbconvert>=5.3.1->phik>=0.9.8->pandas-profiling==2.3.0->-r requirements.txt (line 4)) (0.3)\n",
            "Requirement already satisfied: defusedxml in /usr/local/lib/python3.6/dist-packages (from nbconvert>=5.3.1->phik>=0.9.8->pandas-profiling==2.3.0->-r requirements.txt (line 4)) (0.6.0)\n",
            "Requirement already satisfied: testpath in /usr/local/lib/python3.6/dist-packages (from nbconvert>=5.3.1->phik>=0.9.8->pandas-profiling==2.3.0->-r requirements.txt (line 4)) (0.4.2)\n",
            "Requirement already satisfied: jupyter-core in /usr/local/lib/python3.6/dist-packages (from nbconvert>=5.3.1->phik>=0.9.8->pandas-profiling==2.3.0->-r requirements.txt (line 4)) (4.5.0)\n",
            "Requirement already satisfied: nbformat>=4.4 in /usr/local/lib/python3.6/dist-packages (from nbconvert>=5.3.1->phik>=0.9.8->pandas-profiling==2.3.0->-r requirements.txt (line 4)) (4.4.0)\n",
            "Requirement already satisfied: pyzmq>=13 in /usr/local/lib/python3.6/dist-packages (from jupyter-client>=5.2.3->phik>=0.9.8->pandas-profiling==2.3.0->-r requirements.txt (line 4)) (17.0.0)\n",
            "Requirement already satisfied: tornado>=4.1 in /usr/local/lib/python3.6/dist-packages (from jupyter-client>=5.2.3->phik>=0.9.8->pandas-profiling==2.3.0->-r requirements.txt (line 4)) (4.5.3)\n",
            "Requirement already satisfied: atomicwrites>=1.0 in /usr/local/lib/python3.6/dist-packages (from pytest>=4.0.2->phik>=0.9.8->pandas-profiling==2.3.0->-r requirements.txt (line 4)) (1.3.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.6/dist-packages (from pytest>=4.0.2->phik>=0.9.8->pandas-profiling==2.3.0->-r requirements.txt (line 4)) (19.1)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.6/dist-packages (from pytest>=4.0.2->phik>=0.9.8->pandas-profiling==2.3.0->-r requirements.txt (line 4)) (0.1.7)\n",
            "Requirement already satisfied: importlib-metadata>=0.12; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from pytest>=4.0.2->phik>=0.9.8->pandas-profiling==2.3.0->-r requirements.txt (line 4)) (0.20)\n",
            "Requirement already satisfied: py>=1.5.0 in /usr/local/lib/python3.6/dist-packages (from pytest>=4.0.2->phik>=0.9.8->pandas-profiling==2.3.0->-r requirements.txt (line 4)) (1.8.0)\n",
            "Collecting pluggy<1.0,>=0.12 (from pytest>=4.0.2->phik>=0.9.8->pandas-profiling==2.3.0->-r requirements.txt (line 4))\n",
            "  Downloading https://files.pythonhosted.org/packages/92/c7/48439f7d5fd6bddb4c04b850bb862b42e3e2b98570040dfaf68aedd8114b/pluggy-0.13.0-py2.py3-none-any.whl\n",
            "Requirement already satisfied: more-itertools>=4.0.0 in /usr/local/lib/python3.6/dist-packages (from pytest>=4.0.2->phik>=0.9.8->pandas-profiling==2.3.0->-r requirements.txt (line 4)) (7.2.0)\n",
            "Collecting pylint>=1.4.5 (from pytest-pylint>=0.13.0->phik>=0.9.8->pandas-profiling==2.3.0->-r requirements.txt (line 4))\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/60/c2/b3f73f4ac008bef6e75bca4992f3963b3f85942e0277237721ef1c151f0d/pylint-2.3.1-py3-none-any.whl (765kB)\n",
            "\u001b[K     |████████████████████████████████| 768kB 39.9MB/s \n",
            "\u001b[?25hRequirement already satisfied: ipython-genutils in /usr/local/lib/python3.6/dist-packages (from traitlets>=4.2->ipython->shap==0.30.0->-r requirements.txt (line 9)) (0.2.0)\n",
            "Requirement already satisfied: ptyprocess>=0.5 in /usr/local/lib/python3.6/dist-packages (from pexpect; sys_platform != \"win32\"->ipython->shap==0.30.0->-r requirements.txt (line 9)) (0.6.0)\n",
            "Requirement already satisfied: olefile in /usr/local/lib/python3.6/dist-packages (from pillow>=4.3.0->scikit-image->shap==0.30.0->-r requirements.txt (line 9)) (0.46)\n",
            "Requirement already satisfied: webencodings in /usr/local/lib/python3.6/dist-packages (from bleach->nbconvert>=5.3.1->phik>=0.9.8->pandas-profiling==2.3.0->-r requirements.txt (line 4)) (0.5.1)\n",
            "Requirement already satisfied: jsonschema!=2.5.0,>=2.4 in /usr/local/lib/python3.6/dist-packages (from nbformat>=4.4->nbconvert>=5.3.1->phik>=0.9.8->pandas-profiling==2.3.0->-r requirements.txt (line 4)) (2.6.0)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.6/dist-packages (from importlib-metadata>=0.12; python_version < \"3.8\"->pytest>=4.0.2->phik>=0.9.8->pandas-profiling==2.3.0->-r requirements.txt (line 4)) (0.6.0)\n",
            "Collecting astroid<3,>=2.2.0 (from pylint>=1.4.5->pytest-pylint>=0.13.0->phik>=0.9.8->pandas-profiling==2.3.0->-r requirements.txt (line 4))\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d5/ad/7221a62a2dbce5c3b8c57fd18e1052c7331adc19b3f27f1561aa6e620db2/astroid-2.2.5-py3-none-any.whl (193kB)\n",
            "\u001b[K     |████████████████████████████████| 194kB 53.4MB/s \n",
            "\u001b[?25hCollecting isort<5,>=4.2.5 (from pylint>=1.4.5->pytest-pylint>=0.13.0->phik>=0.9.8->pandas-profiling==2.3.0->-r requirements.txt (line 4))\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/e5/b0/c121fd1fa3419ea9bfd55c7f9c4fedfec5143208d8c7ad3ce3db6c623c21/isort-4.3.21-py2.py3-none-any.whl (42kB)\n",
            "\u001b[K     |████████████████████████████████| 51kB 22.5MB/s \n",
            "\u001b[?25hCollecting mccabe<0.7,>=0.6 (from pylint>=1.4.5->pytest-pylint>=0.13.0->phik>=0.9.8->pandas-profiling==2.3.0->-r requirements.txt (line 4))\n",
            "  Downloading https://files.pythonhosted.org/packages/87/89/479dc97e18549e21354893e4ee4ef36db1d237534982482c3681ee6e7b57/mccabe-0.6.1-py2.py3-none-any.whl\n",
            "Collecting lazy-object-proxy (from astroid<3,>=2.2.0->pylint>=1.4.5->pytest-pylint>=0.13.0->phik>=0.9.8->pandas-profiling==2.3.0->-r requirements.txt (line 4))\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/0e/26/534a6d32572a9dbca11619321535c0a7ab34688545d9d67c2c204b9e3a3d/lazy_object_proxy-1.4.2-cp36-cp36m-manylinux1_x86_64.whl (49kB)\n",
            "\u001b[K     |████████████████████████████████| 51kB 21.0MB/s \n",
            "\u001b[?25hCollecting typed-ast>=1.3.0; implementation_name == \"cpython\" (from astroid<3,>=2.2.0->pylint>=1.4.5->pytest-pylint>=0.13.0->phik>=0.9.8->pandas-profiling==2.3.0->-r requirements.txt (line 4))\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/31/d3/9d1802c161626d0278bafb1ffb32f76b9d01e123881bbf9d91e8ccf28e18/typed_ast-1.4.0-cp36-cp36m-manylinux1_x86_64.whl (736kB)\n",
            "\u001b[K     |████████████████████████████████| 737kB 41.9MB/s \n",
            "\u001b[?25hRequirement already satisfied: wrapt in /usr/local/lib/python3.6/dist-packages (from astroid<3,>=2.2.0->pylint>=1.4.5->pytest-pylint>=0.13.0->phik>=0.9.8->pandas-profiling==2.3.0->-r requirements.txt (line 4)) (1.11.2)\n",
            "Building wheels for collected packages: pandas-profiling, pdpbox, shap, htmlmin, confuse\n",
            "  Building wheel for pandas-profiling (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pandas-profiling: filename=pandas_profiling-2.3.0-py2.py3-none-any.whl size=145035 sha256=0a86d096fff4b017002869d326b38f57497540328203a462f74a4767c651bf48\n",
            "  Stored in directory: /root/.cache/pip/wheels/ce/c7/f1/dbfef4848ebb048cb1d4a22d1ed0c62d8ff2523747235e19fe\n",
            "  Building wheel for pdpbox (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pdpbox: filename=PDPbox-0.2.0-cp36-none-any.whl size=57690723 sha256=7706f5f976ed13aed0684f82d9f49a99e9c3d025bc78b7a87c59e322958333c3\n",
            "  Stored in directory: /root/.cache/pip/wheels/7d/08/51/63fd122b04a2c87d780464eeffb94867c75bd96a64d500a3fe\n",
            "  Building wheel for shap (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for shap: filename=shap-0.30.0-cp36-cp36m-linux_x86_64.whl size=356755 sha256=3425c48ee920660d1baeed451475e58b52bec45ddb8e7b644a3e47daddeec975\n",
            "  Stored in directory: /root/.cache/pip/wheels/67/7a/5b/34feab81170fb8bf642a7536b5127e54e00bce373564435808\n",
            "  Building wheel for htmlmin (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for htmlmin: filename=htmlmin-0.1.12-cp36-none-any.whl size=27084 sha256=3988274dbd0fbf0a2e6c3e2c122dce08e85c39b0e3dcf19fe68dbf7cd3f56601\n",
            "  Stored in directory: /root/.cache/pip/wheels/43/07/ac/7c5a9d708d65247ac1f94066cf1db075540b85716c30255459\n",
            "  Building wheel for confuse (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for confuse: filename=confuse-1.0.0-cp36-none-any.whl size=17486 sha256=84308d98bfcb8152da520b4cc05127f4c363764efef2bc505106fce980eb2054\n",
            "  Stored in directory: /root/.cache/pip/wheels/b0/b2/96/2074eee7dbf7b7df69d004c9b6ac4e32dad04fb7666cf943bd\n",
            "Successfully built pandas-profiling pdpbox shap htmlmin confuse\n",
            "\u001b[31mERROR: datascience 0.10.6 has requirement folium==0.2.1, but you'll have folium 0.8.3 which is incompatible.\u001b[0m\n",
            "Installing collected packages: category-encoders, eli5, htmlmin, pluggy, pytest, lazy-object-proxy, typed-ast, astroid, isort, mccabe, pylint, pytest-pylint, phik, confuse, pandas-profiling, pdpbox, shap\n",
            "  Found existing installation: pluggy 0.7.1\n",
            "    Uninstalling pluggy-0.7.1:\n",
            "      Successfully uninstalled pluggy-0.7.1\n",
            "  Found existing installation: pytest 3.6.4\n",
            "    Uninstalling pytest-3.6.4:\n",
            "      Successfully uninstalled pytest-3.6.4\n",
            "  Found existing installation: pandas-profiling 1.4.1\n",
            "    Uninstalling pandas-profiling-1.4.1:\n",
            "      Successfully uninstalled pandas-profiling-1.4.1\n",
            "Successfully installed astroid-2.2.5 category-encoders-2.0.0 confuse-1.0.0 eli5-0.10.1 htmlmin-0.1.12 isort-4.3.21 lazy-object-proxy-1.4.2 mccabe-0.6.1 pandas-profiling-2.3.0 pdpbox-0.2.0 phik-0.9.8 pluggy-0.13.0 pylint-2.3.1 pytest-5.1.2 pytest-pylint-0.14.1 shap-0.30.0 typed-ast-1.4.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z-TExplb_Slf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Merge train_features.csv & train_labels.csv\n",
        "train = pd.merge(pd.read_csv('../data/tanzania/train_features.csv'), \n",
        "                 pd.read_csv('../data/tanzania/train_labels.csv'))\n",
        "\n",
        "# Read test_features.csv & sample_submission.csv\n",
        "test = pd.read_csv('../data/tanzania/test_features.csv')\n",
        "sample_submission = pd.read_csv('../data/tanzania/sample_submission.csv')\n",
        "\n",
        "\n",
        "# Split train into train & val\n",
        "train, val = train_test_split(train, train_size=0.80, test_size=0.20, \n",
        "                              stratify=train['status_group'], random_state=42)\n",
        "\n",
        "\n",
        "def wrangle(X):\n",
        "    \"\"\"Wrangle train, validate, and test sets in the same way\"\"\"\n",
        "    \n",
        "    # Prevent SettingWithCopyWarning\n",
        "    X = X.copy()\n",
        "    \n",
        "    # About 3% of the time, latitude has small values near zero,\n",
        "    # outside Tanzania, so we'll treat these values like zero.\n",
        "    X['latitude'] = X['latitude'].replace(-2e-08, 0)\n",
        "    \n",
        "    # When columns have zeros and shouldn't, they are like null values.\n",
        "    # So we will replace the zeros with nulls, and impute missing values later.\n",
        "    # Also create a \"missing indicator\" column, because the fact that\n",
        "    # values are missing may be a predictive signal.\n",
        "    cols_with_zeros = ['longitude', 'latitude', 'construction_year', \n",
        "                       'gps_height', 'population']\n",
        "    for col in cols_with_zeros:\n",
        "        X[col] = X[col].replace(0, np.nan)\n",
        "        X[col+'_MISSING'] = X[col].isnull()\n",
        "            \n",
        "    # Drop duplicate columns\n",
        "    duplicates = ['quantity_group', 'payment_type']\n",
        "    X = X.drop(columns=duplicates)\n",
        "    \n",
        "    # Drop recorded_by (never varies) and id (always varies, random)\n",
        "    unusable_variance = ['recorded_by', 'id']\n",
        "    X = X.drop(columns=unusable_variance)\n",
        "    \n",
        "    # Convert date_recorded to datetime\n",
        "    X['date_recorded'] = pd.to_datetime(X['date_recorded'], infer_datetime_format=True)\n",
        "    \n",
        "    # Extract components from date_recorded, then drop the original column\n",
        "    X['year_recorded'] = X['date_recorded'].dt.year\n",
        "    X['month_recorded'] = X['date_recorded'].dt.month\n",
        "    X['day_recorded'] = X['date_recorded'].dt.day\n",
        "    X = X.drop(columns='date_recorded')\n",
        "    \n",
        "    # Engineer feature: how many years from construction_year to date_recorded\n",
        "    X['years'] = X['year_recorded'] - X['construction_year']\n",
        "    X['years_MISSING'] = X['years'].isnull()\n",
        "    \n",
        "    # return the wrangled dataframe\n",
        "    return X\n",
        "\n",
        "train = wrangle(train)\n",
        "val = wrangle(val)\n",
        "test = wrangle(test)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rhg8PQKt_jzP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Arrange data into X features matrix and y target vector\n",
        "target = 'status_group'\n",
        "X_train = train.drop(columns=target)\n",
        "y_train = train[target]\n",
        "X_val = val.drop(columns=target)\n",
        "y_val = val[target]\n",
        "X_test = test"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m8lB4z5l_eml",
        "colab_type": "code",
        "outputId": "34b4227a-d841-4bd9-903f-9fa436ab07a1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "import category_encoders as ce\n",
        "from sklearn.impute import SimpleImputer\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.pipeline import make_pipeline\n",
        "\n",
        "pipeline = make_pipeline(\n",
        "    ce.OrdinalEncoder(), \n",
        "    SimpleImputer(strategy='median'), \n",
        "    RandomForestClassifier(n_estimators=100, random_state=42, n_jobs=-1)\n",
        ")\n",
        "\n",
        "# Fit on train, score on val\n",
        "pipeline.fit(X_train, y_train)\n",
        "print('Validation Accuracy', pipeline.score(X_val, y_val))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Validation Accuracy 0.8135521885521886\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "7HOayKBOYiit"
      },
      "source": [
        "# 3 types of feature importances"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "4bRhsxENYiiu"
      },
      "source": [
        "## 1. (Default) Feature Importances\n",
        "\n",
        "Fastest, good for first estimates, but be aware:\n",
        "\n",
        "\n",
        "\n",
        ">**When the dataset has two (or more) correlated features, then from the point of view of the model, any of these correlated features can be used as the predictor, with no concrete preference of one over the others.** But once one of them is used, the importance of others is significantly reduced since effectively the impurity they can remove is already removed by the first feature. As a consequence, they will have a lower reported importance. This is not an issue when we want to use feature selection to reduce overfitting, since it makes sense to remove features that are mostly duplicated by other features. But when interpreting the data, it can lead to the incorrect conclusion that one of the variables is a strong predictor while the others in the same group are unimportant, while actually they are very close in terms of their relationship with the response variable. — [Selecting good features – Part III: random forests](https://blog.datadive.net/selecting-good-features-part-iii-random-forests/) \n",
        "\n",
        "\n",
        " \n",
        " > **The scikit-learn Random Forest feature importance ... tends to inflate the importance of continuous or high-cardinality categorical variables.** ... Breiman and Cutler, the inventors of Random Forests, indicate that this method of “adding up the gini decreases for each individual variable over all trees in the forest gives a **fast** variable importance that is often very consistent with the permutation importance measure.” —  [Beware Default Random Forest Importances](https://explained.ai/rf-importance/index.html)\n",
        "\n",
        " \n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "BNVm6f7mYiiu",
        "outputId": "6551edf2-7153-4008-c5c3-a3f7c70d72cc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 607
        }
      },
      "source": [
        "# Get feature importances\n",
        "rf = pipeline.named_steps['randomforestclassifier']\n",
        "importances = pd.Series(rf.feature_importances_, X_train.columns)\n",
        "\n",
        "# Plot feature importances\n",
        "%matplotlib inline\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "n = 20\n",
        "plt.figure(figsize=(10,n/2))\n",
        "plt.title(f'Top {n} features')\n",
        "importances.sort_values()[-n:].plot.barh(color='grey');"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAArkAAAJOCAYAAACzyR8VAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n99A0istCZwAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 720x720 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "y8HzLcCBYiiv"
      },
      "source": [
        "## 2. Drop-Column Importance\n",
        "\n",
        "The best in theory, but too slow in practice"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "DQAOlERnYiiw",
        "outputId": "52e7c37d-cb4b-444d-9326-f848941bcb1f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 69
        }
      },
      "source": [
        "column = 'quantity'\n",
        "\n",
        "# Fit without column\n",
        "pipeline = make_pipeline(\n",
        "    ce.OrdinalEncoder(), \n",
        "    SimpleImputer(strategy='median'), \n",
        "    RandomForestClassifier(n_estimators=100, random_state=42, n_jobs=-1)\n",
        ")\n",
        "pipeline.fit(X_train.drop(columns=column), y_train)\n",
        "score_without = pipeline.score(X_val.drop(columns=column), y_val)\n",
        "print(f'Validation Accuracy without {column}: {score_without}')\n",
        "\n",
        "# Fit with column\n",
        "pipeline = make_pipeline(\n",
        "    ce.OrdinalEncoder(), \n",
        "    SimpleImputer(strategy='median'), \n",
        "    RandomForestClassifier(n_estimators=100, random_state=42, n_jobs=-1)\n",
        ")\n",
        "pipeline.fit(X_train, y_train)\n",
        "score_with = pipeline.score(X_val, y_val)\n",
        "print(f'Validation Accuracy with {column}: {score_with}')\n",
        "\n",
        "# Compare the error with & without column\n",
        "print(f'Drop-Column Importance for {column}: {score_with - score_without}')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Validation Accuracy without quantity: 0.7771043771043771\n",
            "Validation Accuracy with quantity: 0.8135521885521886\n",
            "Drop-Column Importance for quantity: 0.03644781144781151\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "6Vu39wGkYiix"
      },
      "source": [
        "## 3. Permutation Importance\n",
        "\n",
        "Permutation Importance is a good compromise between Feature Importance based on impurity reduction (which is the fastest) and Drop Column Importance (which is the \"best.\")\n",
        "\n",
        "[The ELI5 library documentation explains,](https://eli5.readthedocs.io/en/latest/blackbox/permutation_importance.html)\n",
        "\n",
        "> Importance can be measured by looking at how much the score (accuracy, F1, R^2, etc. - any score we’re interested in) decreases when a feature is not available.\n",
        ">\n",
        "> To do that one can remove feature from the dataset, re-train the estimator and check the score. But it requires re-training an estimator for each feature, which can be computationally intensive. ...\n",
        ">\n",
        ">To avoid re-training the estimator we can remove a feature only from the test part of the dataset, and compute score without using this feature. It doesn’t work as-is, because estimators expect feature to be present. So instead of removing a feature we can replace it with random noise - feature column is still there, but it no longer contains useful information. This method works if noise is drawn from the same distribution as original feature values (as otherwise estimator may fail). The simplest way to get such noise is to shuffle values for a feature, i.e. use other examples’ feature values - this is how permutation importance is computed.\n",
        ">\n",
        ">The method is most suitable for computing feature importances when a number of columns (features) is not huge; it can be resource-intensive otherwise."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "GYCiEx7zYiiy"
      },
      "source": [
        "### Do-It-Yourself way, for intuition"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "TksOf_n2Yiiy",
        "outputId": "22f8d4a5-df9b-4aa9-83dd-c4defb96a80d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 121
        }
      },
      "source": [
        "# BEFORE: Sequence\n",
        "feature = 'quantity'\n",
        "X_val[feature].head()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "3290     insufficient\n",
              "47666    insufficient\n",
              "2538           enough\n",
              "53117          enough\n",
              "51817          enough\n",
              "Name: quantity, dtype: object"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vWJKuKlIFL8M",
        "colab_type": "code",
        "outputId": "36b59812-f35d-4f8c-bc65-a168991ea08f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 121
        }
      },
      "source": [
        "# BEFORE: Distribution\n",
        "X_val[feature].value_counts()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "enough          6619\n",
              "insufficient    2976\n",
              "dry             1325\n",
              "seasonal         806\n",
              "unknown          154\n",
              "Name: quantity, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u4_w-iL9FTu8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# PERMUTE!\n",
        "X_val_permuted = X_val.copy()\n",
        "X_val_permuted[feature] = np.random.permutation(X_val[feature])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PsGKdQzVFnP4",
        "colab_type": "code",
        "outputId": "ca2ebaa2-7b12-4cea-fb66-f096dfeebf79",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 121
        }
      },
      "source": [
        "# AFTER: Sequence has changed!\n",
        "X_val_permuted[feature].head()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "3290     enough\n",
              "47666    enough\n",
              "2538     enough\n",
              "53117    enough\n",
              "51817       dry\n",
              "Name: quantity, dtype: object"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ezWi8KHgFouP",
        "colab_type": "code",
        "outputId": "016af245-6d45-44b2-c273-42719db7856a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 121
        }
      },
      "source": [
        "# AFTER: Distribution hasn't changed!\n",
        "X_val_permuted[feature].value_counts()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "enough          6619\n",
              "insufficient    2976\n",
              "dry             1325\n",
              "seasonal         806\n",
              "unknown          154\n",
              "Name: quantity, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6deSIimPF7hZ",
        "colab_type": "code",
        "outputId": "2ac96837-3d25-482e-f8b4-890ccc56c879",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 69
        }
      },
      "source": [
        "# Get the permutation importance\n",
        "# Notice that we don't need to refit the pipeline here!\n",
        "score_permuted = pipeline.score(X_val_permuted, y_val)\n",
        "\n",
        "print(f'Validation Accuracy with {feature}: {score_with}')\n",
        "print(f'Validation Accuracy with {feature} permuted: {score_permuted}')\n",
        "print(f'Permutation Importance: {score_with - score_permuted}')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Validation Accuracy with quantity: 0.8135521885521886\n",
            "Validation Accuracy with quantity permuted: 0.7090909090909091\n",
            "Permutation Importance: 0.10446127946127948\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cbbAFVwfGX1p",
        "colab_type": "code",
        "outputId": "bb82656c-c6b4-4bd5-b5ec-7e5a3cf35560",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 69
        }
      },
      "source": [
        "# Rerun the permutation importance process, but for a different feature\n",
        "feature = 'wpt_name'\n",
        "X_val_permuted = X_val.copy()\n",
        "X_val_permuted[feature] = np.random.permutation(X_val[feature])\n",
        "score_permuted = pipeline.score(X_val_permuted, y_val)\n",
        "\n",
        "print(f'Validation Accuracy with {feature}: {score_with}')\n",
        "print(f'Validation Accuracy with {feature} permuted: {score_permuted}')\n",
        "print(f'Permutation Importance: {score_with - score_permuted}')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Validation Accuracy with wpt_name: 0.8135521885521886\n",
            "Validation Accuracy with wpt_name permuted: 0.8132154882154882\n",
            "Permutation Importance: 0.0003367003367004129\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "0LYk19SNYii7"
      },
      "source": [
        "### With eli5 library\n",
        "\n",
        "For more documentation on using this library, see:\n",
        "- [eli5.sklearn.PermutationImportance](https://eli5.readthedocs.io/en/latest/autodocs/sklearn.html#eli5.sklearn.permutation_importance.PermutationImportance)\n",
        "- [eli5.show_weights](https://eli5.readthedocs.io/en/latest/autodocs/eli5.html#eli5.show_weights)\n",
        "- [scikit-learn user guide, `scoring` parameter](https://scikit-learn.org/stable/modules/model_evaluation.html#the-scoring-parameter-defining-model-evaluation-rules)\n",
        "\n",
        "eli5 doesn't work with pipelines."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uooPLjX0HkQv",
        "colab_type": "code",
        "outputId": "dc28d861-705d-426a-eb33-9fabf0fe7c58",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 139
        }
      },
      "source": [
        "transformers = make_pipeline(\n",
        "    ce.OrdinalEncoder(), \n",
        "    SimpleImputer(strategy='median')\n",
        ")\n",
        "\n",
        "X_train_transformed = transformers.fit_transform(X_train)\n",
        "X_val_transformed = transformers.transform(X_val)\n",
        "\n",
        "model = RandomForestClassifier(n_estimators=100, random_state=42, n_jobs=-1)\n",
        "model.fit(X_train_transformed, y_train)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
              "                       max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
              "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
              "                       min_samples_leaf=1, min_samples_split=2,\n",
              "                       min_weight_fraction_leaf=0.0, n_estimators=100,\n",
              "                       n_jobs=-1, oob_score=False, random_state=42, verbose=0,\n",
              "                       warm_start=False)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hpSemTkFFP8i",
        "colab_type": "code",
        "outputId": "93dea101-7b42-4f47-b9ac-3d9220b70458",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 832
        }
      },
      "source": [
        "import eli5\n",
        "from eli5.sklearn import PermutationImportance\n",
        "\n",
        "permuter = PermutationImportance(\n",
        "    model,\n",
        "    scoring='accuracy', \n",
        "    n_iter=2, \n",
        "    random_state=42\n",
        ")\n",
        "\n",
        "permuter.fit(X_val_transformed, y_val)\n",
        "feature_names = X_val.columns.tolist()\n",
        "\n",
        "eli5.show_weights(\n",
        "    permuter, \n",
        "    top=None, # show permutation importances for all features\n",
        "    feature_names=feature_names\n",
        ")"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "\n",
              "    <style>\n",
              "    table.eli5-weights tr:hover {\n",
              "        filter: brightness(85%);\n",
              "    }\n",
              "</style>\n",
              "\n",
              "\n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "        <table class=\"eli5-weights eli5-feature-importances\" style=\"border-collapse: collapse; border: none; margin-top: 0em; table-layout: auto;\">\n",
              "    <thead>\n",
              "    <tr style=\"border: none;\">\n",
              "        <th style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">Weight</th>\n",
              "        <th style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">Feature</th>\n",
              "    </tr>\n",
              "    </thead>\n",
              "    <tbody>\n",
              "    \n",
              "        <tr style=\"background-color: hsl(120, 100.00%, 80.00%); border: none;\">\n",
              "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
              "                0.1005\n",
              "                \n",
              "                    &plusmn; 0.0003\n",
              "                \n",
              "            </td>\n",
              "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
              "                quantity\n",
              "            </td>\n",
              "        </tr>\n",
              "    \n",
              "        <tr style=\"background-color: hsl(120, 100.00%, 95.88%); border: none;\">\n",
              "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
              "                0.0105\n",
              "                \n",
              "                    &plusmn; 0.0005\n",
              "                \n",
              "            </td>\n",
              "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
              "                amount_tsh\n",
              "            </td>\n",
              "        </tr>\n",
              "    \n",
              "        <tr style=\"background-color: hsl(120, 100.00%, 95.92%); border: none;\">\n",
              "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
              "                0.0104\n",
              "                \n",
              "                    &plusmn; 0.0012\n",
              "                \n",
              "            </td>\n",
              "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
              "                waterpoint_type\n",
              "            </td>\n",
              "        </tr>\n",
              "    \n",
              "        <tr style=\"background-color: hsl(120, 100.00%, 96.02%); border: none;\">\n",
              "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
              "                0.0100\n",
              "                \n",
              "                    &plusmn; 0.0005\n",
              "                \n",
              "            </td>\n",
              "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
              "                extraction_type_class\n",
              "            </td>\n",
              "        </tr>\n",
              "    \n",
              "        <tr style=\"background-color: hsl(120, 100.00%, 96.15%); border: none;\">\n",
              "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
              "                0.0096\n",
              "                \n",
              "                    &plusmn; 0.0013\n",
              "                \n",
              "            </td>\n",
              "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
              "                longitude\n",
              "            </td>\n",
              "        </tr>\n",
              "    \n",
              "        <tr style=\"background-color: hsl(120, 100.00%, 96.74%); border: none;\">\n",
              "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
              "                0.0075\n",
              "                \n",
              "                    &plusmn; 0.0019\n",
              "                \n",
              "            </td>\n",
              "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
              "                latitude\n",
              "            </td>\n",
              "        </tr>\n",
              "    \n",
              "        <tr style=\"background-color: hsl(120, 100.00%, 96.89%); border: none;\">\n",
              "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
              "                0.0070\n",
              "                \n",
              "                    &plusmn; 0.0011\n",
              "                \n",
              "            </td>\n",
              "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
              "                waterpoint_type_group\n",
              "            </td>\n",
              "        </tr>\n",
              "    \n",
              "        <tr style=\"background-color: hsl(120, 100.00%, 97.09%); border: none;\">\n",
              "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
              "                0.0064\n",
              "                \n",
              "                    &plusmn; 0.0003\n",
              "                \n",
              "            </td>\n",
              "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
              "                population\n",
              "            </td>\n",
              "        </tr>\n",
              "    \n",
              "        <tr style=\"background-color: hsl(120, 100.00%, 98.08%); border: none;\">\n",
              "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
              "                0.0035\n",
              "                \n",
              "                    &plusmn; 0.0034\n",
              "                \n",
              "            </td>\n",
              "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
              "                construction_year\n",
              "            </td>\n",
              "        </tr>\n",
              "    \n",
              "        <tr style=\"background-color: hsl(120, 100.00%, 98.28%); border: none;\">\n",
              "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
              "                0.0030\n",
              "                \n",
              "                    &plusmn; 0.0035\n",
              "                \n",
              "            </td>\n",
              "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
              "                years\n",
              "            </td>\n",
              "        </tr>\n",
              "    \n",
              "        <tr style=\"background-color: hsl(120, 100.00%, 98.33%); border: none;\">\n",
              "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
              "                0.0029\n",
              "                \n",
              "                    &plusmn; 0.0006\n",
              "                \n",
              "            </td>\n",
              "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
              "                public_meeting\n",
              "            </td>\n",
              "        </tr>\n",
              "    \n",
              "        <tr style=\"background-color: hsl(120, 100.00%, 98.36%); border: none;\">\n",
              "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
              "                0.0028\n",
              "                \n",
              "                    &plusmn; 0.0011\n",
              "                \n",
              "            </td>\n",
              "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
              "                subvillage\n",
              "            </td>\n",
              "        </tr>\n",
              "    \n",
              "        <tr style=\"background-color: hsl(120, 100.00%, 98.36%); border: none;\">\n",
              "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
              "                0.0028\n",
              "                \n",
              "                    &plusmn; 0.0013\n",
              "                \n",
              "            </td>\n",
              "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
              "                payment\n",
              "            </td>\n",
              "        </tr>\n",
              "    \n",
              "        <tr style=\"background-color: hsl(120, 100.00%, 98.57%); border: none;\">\n",
              "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
              "                0.0023\n",
              "                \n",
              "                    &plusmn; 0.0018\n",
              "                \n",
              "            </td>\n",
              "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
              "                day_recorded\n",
              "            </td>\n",
              "        </tr>\n",
              "    \n",
              "        <tr style=\"background-color: hsl(120, 100.00%, 98.80%); border: none;\">\n",
              "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
              "                0.0018\n",
              "                \n",
              "                    &plusmn; 0.0004\n",
              "                \n",
              "            </td>\n",
              "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
              "                gps_height\n",
              "            </td>\n",
              "        </tr>\n",
              "    \n",
              "        <tr style=\"background-color: hsl(120, 100.00%, 98.88%); border: none;\">\n",
              "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
              "                0.0016\n",
              "                \n",
              "                    &plusmn; 0.0008\n",
              "                \n",
              "            </td>\n",
              "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
              "                source\n",
              "            </td>\n",
              "        </tr>\n",
              "    \n",
              "        <tr style=\"background-color: hsl(120, 100.00%, 98.94%); border: none;\">\n",
              "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
              "                0.0015\n",
              "                \n",
              "                    &plusmn; 0.0008\n",
              "                \n",
              "            </td>\n",
              "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
              "                district_code\n",
              "            </td>\n",
              "        </tr>\n",
              "    \n",
              "        <tr style=\"background-color: hsl(120, 100.00%, 99.00%); border: none;\">\n",
              "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
              "                0.0014\n",
              "                \n",
              "                    &plusmn; 0.0008\n",
              "                \n",
              "            </td>\n",
              "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
              "                extraction_type_group\n",
              "            </td>\n",
              "        </tr>\n",
              "    \n",
              "        <tr style=\"background-color: hsl(120, 100.00%, 99.18%); border: none;\">\n",
              "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
              "                0.0011\n",
              "                \n",
              "                    &plusmn; 0.0016\n",
              "                \n",
              "            </td>\n",
              "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
              "                region\n",
              "            </td>\n",
              "        </tr>\n",
              "    \n",
              "        <tr style=\"background-color: hsl(120, 100.00%, 99.25%); border: none;\">\n",
              "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
              "                0.0009\n",
              "                \n",
              "                    &plusmn; 0.0010\n",
              "                \n",
              "            </td>\n",
              "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
              "                longitude_MISSING\n",
              "            </td>\n",
              "        </tr>\n",
              "    \n",
              "        <tr style=\"background-color: hsl(120, 100.00%, 99.27%); border: none;\">\n",
              "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
              "                0.0009\n",
              "                \n",
              "                    &plusmn; 0.0006\n",
              "                \n",
              "            </td>\n",
              "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
              "                extraction_type\n",
              "            </td>\n",
              "        </tr>\n",
              "    \n",
              "        <tr style=\"background-color: hsl(120, 100.00%, 99.32%); border: none;\">\n",
              "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
              "                0.0008\n",
              "                \n",
              "                    &plusmn; 0.0006\n",
              "                \n",
              "            </td>\n",
              "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
              "                ward\n",
              "            </td>\n",
              "        </tr>\n",
              "    \n",
              "        <tr style=\"background-color: hsl(120, 100.00%, 99.35%); border: none;\">\n",
              "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
              "                0.0008\n",
              "                \n",
              "                    &plusmn; 0.0010\n",
              "                \n",
              "            </td>\n",
              "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
              "                year_recorded\n",
              "            </td>\n",
              "        </tr>\n",
              "    \n",
              "        <tr style=\"background-color: hsl(120, 100.00%, 99.35%); border: none;\">\n",
              "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
              "                0.0008\n",
              "                \n",
              "                    &plusmn; 0.0007\n",
              "                \n",
              "            </td>\n",
              "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
              "                wpt_name\n",
              "            </td>\n",
              "        </tr>\n",
              "    \n",
              "        <tr style=\"background-color: hsl(120, 100.00%, 99.37%); border: none;\">\n",
              "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
              "                0.0007\n",
              "                \n",
              "                    &plusmn; 0.0011\n",
              "                \n",
              "            </td>\n",
              "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
              "                water_quality\n",
              "            </td>\n",
              "        </tr>\n",
              "    \n",
              "        <tr style=\"background-color: hsl(120, 100.00%, 99.40%); border: none;\">\n",
              "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
              "                0.0007\n",
              "                \n",
              "                    &plusmn; 0.0005\n",
              "                \n",
              "            </td>\n",
              "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
              "                years_MISSING\n",
              "            </td>\n",
              "        </tr>\n",
              "    \n",
              "        <tr style=\"background-color: hsl(120, 100.00%, 99.40%); border: none;\">\n",
              "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
              "                0.0007\n",
              "                \n",
              "                    &plusmn; 0.0005\n",
              "                \n",
              "            </td>\n",
              "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
              "                permit\n",
              "            </td>\n",
              "        </tr>\n",
              "    \n",
              "        <tr style=\"background-color: hsl(120, 100.00%, 99.42%); border: none;\">\n",
              "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
              "                0.0006\n",
              "                \n",
              "                    &plusmn; 0.0004\n",
              "                \n",
              "            </td>\n",
              "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
              "                funder\n",
              "            </td>\n",
              "        </tr>\n",
              "    \n",
              "        <tr style=\"background-color: hsl(120, 100.00%, 99.45%); border: none;\">\n",
              "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
              "                0.0006\n",
              "                \n",
              "                    &plusmn; 0.0010\n",
              "                \n",
              "            </td>\n",
              "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
              "                source_class\n",
              "            </td>\n",
              "        </tr>\n",
              "    \n",
              "        <tr style=\"background-color: hsl(120, 100.00%, 99.48%); border: none;\">\n",
              "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
              "                0.0005\n",
              "                \n",
              "                    &plusmn; 0.0009\n",
              "                \n",
              "            </td>\n",
              "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
              "                lga\n",
              "            </td>\n",
              "        </tr>\n",
              "    \n",
              "        <tr style=\"background-color: hsl(120, 100.00%, 99.48%); border: none;\">\n",
              "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
              "                0.0005\n",
              "                \n",
              "                    &plusmn; 0.0014\n",
              "                \n",
              "            </td>\n",
              "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
              "                region_code\n",
              "            </td>\n",
              "        </tr>\n",
              "    \n",
              "        <tr style=\"background-color: hsl(120, 100.00%, 99.51%); border: none;\">\n",
              "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
              "                0.0005\n",
              "                \n",
              "                    &plusmn; 0.0024\n",
              "                \n",
              "            </td>\n",
              "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
              "                management\n",
              "            </td>\n",
              "        </tr>\n",
              "    \n",
              "        <tr style=\"background-color: hsl(120, 100.00%, 99.54%); border: none;\">\n",
              "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
              "                0.0005\n",
              "                \n",
              "                    &plusmn; 0.0021\n",
              "                \n",
              "            </td>\n",
              "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
              "                month_recorded\n",
              "            </td>\n",
              "        </tr>\n",
              "    \n",
              "        <tr style=\"background-color: hsl(120, 100.00%, 99.57%); border: none;\">\n",
              "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
              "                0.0004\n",
              "                \n",
              "                    &plusmn; 0.0007\n",
              "                \n",
              "            </td>\n",
              "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
              "                construction_year_MISSING\n",
              "            </td>\n",
              "        </tr>\n",
              "    \n",
              "        <tr style=\"background-color: hsl(120, 100.00%, 99.63%); border: none;\">\n",
              "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
              "                0.0003\n",
              "                \n",
              "                    &plusmn; 0.0000\n",
              "                \n",
              "            </td>\n",
              "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
              "                num_private\n",
              "            </td>\n",
              "        </tr>\n",
              "    \n",
              "        <tr style=\"background-color: hsl(120, 100.00%, 99.70%); border: none;\">\n",
              "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
              "                0.0003\n",
              "                \n",
              "                    &plusmn; 0.0003\n",
              "                \n",
              "            </td>\n",
              "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
              "                population_MISSING\n",
              "            </td>\n",
              "        </tr>\n",
              "    \n",
              "        <tr style=\"background-color: hsl(120, 100.00%, 99.81%); border: none;\">\n",
              "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
              "                0.0001\n",
              "                \n",
              "                    &plusmn; 0.0001\n",
              "                \n",
              "            </td>\n",
              "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
              "                latitude_MISSING\n",
              "            </td>\n",
              "        </tr>\n",
              "    \n",
              "        <tr style=\"background-color: hsl(0, 100.00%, 99.91%); border: none;\">\n",
              "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
              "                -0.0000\n",
              "                \n",
              "                    &plusmn; 0.0001\n",
              "                \n",
              "            </td>\n",
              "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
              "                source_type\n",
              "            </td>\n",
              "        </tr>\n",
              "    \n",
              "        <tr style=\"background-color: hsl(0, 100.00%, 99.77%); border: none;\">\n",
              "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
              "                -0.0002\n",
              "                \n",
              "                    &plusmn; 0.0003\n",
              "                \n",
              "            </td>\n",
              "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
              "                scheme_name\n",
              "            </td>\n",
              "        </tr>\n",
              "    \n",
              "        <tr style=\"background-color: hsl(0, 100.00%, 99.77%); border: none;\">\n",
              "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
              "                -0.0002\n",
              "                \n",
              "                    &plusmn; 0.0013\n",
              "                \n",
              "            </td>\n",
              "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
              "                scheme_management\n",
              "            </td>\n",
              "        </tr>\n",
              "    \n",
              "        <tr style=\"background-color: hsl(0, 100.00%, 99.77%); border: none;\">\n",
              "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
              "                -0.0002\n",
              "                \n",
              "                    &plusmn; 0.0003\n",
              "                \n",
              "            </td>\n",
              "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
              "                management_group\n",
              "            </td>\n",
              "        </tr>\n",
              "    \n",
              "        <tr style=\"background-color: hsl(0, 100.00%, 99.77%); border: none;\">\n",
              "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
              "                -0.0002\n",
              "                \n",
              "                    &plusmn; 0.0007\n",
              "                \n",
              "            </td>\n",
              "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
              "                gps_height_MISSING\n",
              "            </td>\n",
              "        </tr>\n",
              "    \n",
              "        <tr style=\"background-color: hsl(0, 100.00%, 99.32%); border: none;\">\n",
              "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
              "                -0.0008\n",
              "                \n",
              "                    &plusmn; 0.0013\n",
              "                \n",
              "            </td>\n",
              "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
              "                installer\n",
              "            </td>\n",
              "        </tr>\n",
              "    \n",
              "        <tr style=\"background-color: hsl(0, 100.00%, 99.27%); border: none;\">\n",
              "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
              "                -0.0009\n",
              "                \n",
              "                    &plusmn; 0.0011\n",
              "                \n",
              "            </td>\n",
              "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
              "                quality_group\n",
              "            </td>\n",
              "        </tr>\n",
              "    \n",
              "        <tr style=\"background-color: hsl(0, 100.00%, 98.78%); border: none;\">\n",
              "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
              "                -0.0019\n",
              "                \n",
              "                    &plusmn; 0.0008\n",
              "                \n",
              "            </td>\n",
              "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
              "                basin\n",
              "            </td>\n",
              "        </tr>\n",
              "    \n",
              "    \n",
              "    </tbody>\n",
              "</table>\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "\n",
              "\n"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "q07yW9k-Yii8"
      },
      "source": [
        "### We can use importances for feature selection\n",
        "\n",
        "For example, we can remove features with zero importance. The model trains faster and the score does not decrease."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "tZrPFyEMYii9",
        "outputId": "5c133476-a815-4148-a359-8df18b2c1e49",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "print('Shape before removing features:', X_train.shape)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Shape before removing features: (47520, 45)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GTWTlO2bLI0F",
        "colab_type": "code",
        "outputId": "14c7c9ab-3ba2-45b1-bf01-52668bb29ca8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "minimum_importance = 0\n",
        "mask = permuter.feature_importances_ > minimum_importance\n",
        "features = X_train.columns[mask]\n",
        "X_train = X_train[features]\n",
        "\n",
        "print('Shape after removing features:', X_train.shape)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Shape after removing features: (47520, 37)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_VsJ483wMAQ6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X_val = X_val[features]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PufJJrFjMCnU",
        "colab_type": "code",
        "outputId": "b1eec33c-a6e8-42c8-d90c-2e621a5f7531",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "pipeline = make_pipeline(\n",
        "    ce.OrdinalEncoder(), \n",
        "    SimpleImputer(strategy='median'), \n",
        "    RandomForestClassifier(n_estimators=100, random_state=42, n_jobs=-1)\n",
        ")\n",
        "\n",
        "# Fit on train, score on val\n",
        "pipeline.fit(X_train, y_train)\n",
        "print('Validation Accuracy', pipeline.score(X_val, y_val))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Validation Accuracy 0.8138047138047138\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fl67bCR7WY6j",
        "colab_type": "text"
      },
      "source": [
        "## Use xgboost for gradient boosting\n",
        "\n",
        "#### [XGBoost Python API Reference: Scikit-Learn API](https://xgboost.readthedocs.io/en/latest/python/python_api.html#module-xgboost.sklearn)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wsnJRKjfWYph",
        "colab_type": "code",
        "outputId": "1dfccefc-8c35-442f-c74f-b447d8ef6e87",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 416
        }
      },
      "source": [
        "from xgboost import XGBClassifier\n",
        "\n",
        "pipeline = make_pipeline(\n",
        "    ce.OrdinalEncoder(), \n",
        "    XGBClassifier(n_estimators=100, random_state=42, n_jobs=-1)\n",
        ")\n",
        "\n",
        "pipeline.fit(X_train, y_train)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Pipeline(memory=None,\n",
              "         steps=[('ordinalencoder',\n",
              "                 OrdinalEncoder(cols=['funder', 'wpt_name', 'subvillage',\n",
              "                                      'region', 'lga', 'ward', 'public_meeting',\n",
              "                                      'permit', 'extraction_type',\n",
              "                                      'extraction_type_group',\n",
              "                                      'extraction_type_class', 'management',\n",
              "                                      'payment', 'water_quality', 'quantity',\n",
              "                                      'source', 'source_class',\n",
              "                                      'waterpoint_type',\n",
              "                                      'waterpoint_type_group'],\n",
              "                                drop_invariant=Fals...\n",
              "                 XGBClassifier(base_score=0.5, booster='gbtree',\n",
              "                               colsample_bylevel=1, colsample_bynode=1,\n",
              "                               colsample_bytree=1, gamma=0, learning_rate=0.1,\n",
              "                               max_delta_step=0, max_depth=3,\n",
              "                               min_child_weight=1, missing=None,\n",
              "                               n_estimators=100, n_jobs=-1, nthread=None,\n",
              "                               objective='multi:softprob', random_state=42,\n",
              "                               reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
              "                               seed=None, silent=None, subsample=1,\n",
              "                               verbosity=1))],\n",
              "         verbose=False)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JgdxExk_PjL-",
        "colab_type": "code",
        "outputId": "6176e50d-373e-4de7-eb74-503ff8b0f8f6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "from sklearn.metrics import accuracy_score\n",
        "y_pred = pipeline.predict(X_val)\n",
        "print('Validation Accuracy', accuracy_score(y_val, y_pred))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Validation Accuracy 0.7454545454545455\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ubb7Ot6OZcK1",
        "colab_type": "text"
      },
      "source": [
        "### Understand the difference between boosting & bagging\n",
        "\n",
        "Boosting (used by Gradient Boosting) is different than Bagging (used by Random Forests). \n",
        "\n",
        "[_An Introduction to Statistical Learning_](http://www-bcf.usc.edu/~gareth/ISL/ISLR%20Seventh%20Printing.pdf) Chapter 8.2.3, Boosting:\n",
        "\n",
        ">Recall that bagging involves creating multiple copies of the original training data set using the bootstrap, fitting a separate decision tree to each copy, and then combining all of the trees in order to create a single predictive model.\n",
        ">\n",
        ">**Boosting works in a similar way, except that the trees are grown _sequentially_: each tree is grown using information from previously grown trees.**\n",
        ">\n",
        ">Unlike fitting a single large decision tree to the data, which amounts to _fitting the data hard_ and potentially overfitting, the boosting approach instead _learns slowly._ Given the current model, we fit a decision tree to the residuals from the model.\n",
        ">\n",
        ">We then add this new decision tree into the fitted function in order to update the residuals. Each of these trees can be rather small, with just a few terminal nodes. **By fitting small trees to the residuals, we slowly improve fˆ in areas where it does not perform well.**\n",
        ">\n",
        ">Note that in boosting, unlike in bagging, the construction of each tree depends strongly on the trees that have already been grown."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eCjVSlD_XJr2",
        "colab_type": "text"
      },
      "source": [
        "#### [Avoid Overfitting By Early Stopping With XGBoost In Python](https://machinelearningmastery.com/avoid-overfitting-by-early-stopping-with-xgboost-in-python/)\n",
        "\n",
        "Why is early stopping better than a For loop, or GridSearchCV, to optimize `n_estimators`?\n",
        "\n",
        "With early stopping, if `n_iterations` is our number of iterations, then we fit `n_iterations` decision trees.\n",
        "\n",
        "With a for loop, or GridSearchCV, we'd fit `sum(range(1,n_rounds+1))` trees.\n",
        "\n",
        "But it doesn't work well with pipelines. You may need to re-run multiple times with different values of other parameters such as `max_depth` and `learning_rate`.\n",
        "\n",
        "#### XGBoost parameters\n",
        "- [Notes on parameter tuning](https://xgboost.readthedocs.io/en/latest/tutorials/param_tuning.html)\n",
        "- [Parameters documentation](https://xgboost.readthedocs.io/en/latest/parameter.html)\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "scp2SgxKR-6x",
        "colab_type": "code",
        "outputId": "ad8bace7-8640-45a0-dcfe-2f89f4ba64bb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "encoder = ce.OrdinalEncoder()\n",
        "X_train_encoded = encoder.fit_transform(X_train)\n",
        "X_val_encoded = encoder.transform(X_val)\n",
        "\n",
        "X_train.shape, X_val.shape, X_train_encoded.shape, X_val_encoded.shape"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((47520, 37), (11880, 37), (47520, 37), (11880, 37))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xAwf54mMSRb3",
        "colab_type": "code",
        "outputId": "618a4516-8627-4331-e789-0192d0317273",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "eval_set = [(X_train_encoded, y_train), \n",
        "            (X_val_encoded, y_val)]\n",
        "\n",
        "model = XGBClassifier(\n",
        "    n_estimators=1000, # <= 1000 trees, depends on early stopping\n",
        "    max_depth=7,       # try deeper trees because of high cardinality categoricals\n",
        "    learning_rate=0.1, # try higher learning rate\n",
        "    n_jobs=-1\n",
        ")\n",
        "\n",
        "model.fit(X_train_encoded, y_train, eval_set=eval_set, \n",
        "          eval_metric='merror', early_stopping_rounds=50)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[0]\tvalidation_0-merror:0.250821\tvalidation_1-merror:0.261027\n",
            "Multiple eval metrics have been passed: 'validation_1-merror' will be used for early stopping.\n",
            "\n",
            "Will train until validation_1-merror hasn't improved in 50 rounds.\n",
            "[1]\tvalidation_0-merror:0.251284\tvalidation_1-merror:0.262795\n",
            "[2]\tvalidation_0-merror:0.252315\tvalidation_1-merror:0.264562\n",
            "[3]\tvalidation_0-merror:0.2504\tvalidation_1-merror:0.26229\n",
            "[4]\tvalidation_0-merror:0.249916\tvalidation_1-merror:0.261448\n",
            "[5]\tvalidation_0-merror:0.246191\tvalidation_1-merror:0.257239\n",
            "[6]\tvalidation_0-merror:0.244171\tvalidation_1-merror:0.253704\n",
            "[7]\tvalidation_0-merror:0.241246\tvalidation_1-merror:0.251515\n",
            "[8]\tvalidation_0-merror:0.237879\tvalidation_1-merror:0.248401\n",
            "[9]\tvalidation_0-merror:0.237037\tvalidation_1-merror:0.247811\n",
            "[10]\tvalidation_0-merror:0.23609\tvalidation_1-merror:0.24697\n",
            "[11]\tvalidation_0-merror:0.234912\tvalidation_1-merror:0.246549\n",
            "[12]\tvalidation_0-merror:0.234154\tvalidation_1-merror:0.246128\n",
            "[13]\tvalidation_0-merror:0.233544\tvalidation_1-merror:0.245455\n",
            "[14]\tvalidation_0-merror:0.232176\tvalidation_1-merror:0.243687\n",
            "[15]\tvalidation_0-merror:0.231187\tvalidation_1-merror:0.243098\n",
            "[16]\tvalidation_0-merror:0.230324\tvalidation_1-merror:0.241751\n",
            "[17]\tvalidation_0-merror:0.228872\tvalidation_1-merror:0.240657\n",
            "[18]\tvalidation_0-merror:0.228199\tvalidation_1-merror:0.24133\n",
            "[19]\tvalidation_0-merror:0.227399\tvalidation_1-merror:0.239394\n",
            "[20]\tvalidation_0-merror:0.226094\tvalidation_1-merror:0.239815\n",
            "[21]\tvalidation_0-merror:0.224811\tvalidation_1-merror:0.238047\n",
            "[22]\tvalidation_0-merror:0.224011\tvalidation_1-merror:0.236448\n",
            "[23]\tvalidation_0-merror:0.222875\tvalidation_1-merror:0.236195\n",
            "[24]\tvalidation_0-merror:0.22218\tvalidation_1-merror:0.235859\n",
            "[25]\tvalidation_0-merror:0.221233\tvalidation_1-merror:0.235017\n",
            "[26]\tvalidation_0-merror:0.219907\tvalidation_1-merror:0.233838\n",
            "[27]\tvalidation_0-merror:0.218056\tvalidation_1-merror:0.232576\n",
            "[28]\tvalidation_0-merror:0.217003\tvalidation_1-merror:0.231397\n",
            "[29]\tvalidation_0-merror:0.215278\tvalidation_1-merror:0.230051\n",
            "[30]\tvalidation_0-merror:0.212689\tvalidation_1-merror:0.229209\n",
            "[31]\tvalidation_0-merror:0.211806\tvalidation_1-merror:0.227694\n",
            "[32]\tvalidation_0-merror:0.210417\tvalidation_1-merror:0.227694\n",
            "[33]\tvalidation_0-merror:0.208628\tvalidation_1-merror:0.226768\n",
            "[34]\tvalidation_0-merror:0.207513\tvalidation_1-merror:0.225842\n",
            "[35]\tvalidation_0-merror:0.206608\tvalidation_1-merror:0.225505\n",
            "[36]\tvalidation_0-merror:0.205114\tvalidation_1-merror:0.224916\n",
            "[37]\tvalidation_0-merror:0.203872\tvalidation_1-merror:0.224579\n",
            "[38]\tvalidation_0-merror:0.203409\tvalidation_1-merror:0.224411\n",
            "[39]\tvalidation_0-merror:0.202778\tvalidation_1-merror:0.223485\n",
            "[40]\tvalidation_0-merror:0.201684\tvalidation_1-merror:0.222138\n",
            "[41]\tvalidation_0-merror:0.200821\tvalidation_1-merror:0.222306\n",
            "[42]\tvalidation_0-merror:0.199579\tvalidation_1-merror:0.22037\n",
            "[43]\tvalidation_0-merror:0.198316\tvalidation_1-merror:0.220707\n",
            "[44]\tvalidation_0-merror:0.19718\tvalidation_1-merror:0.219865\n",
            "[45]\tvalidation_0-merror:0.196317\tvalidation_1-merror:0.219529\n",
            "[46]\tvalidation_0-merror:0.196233\tvalidation_1-merror:0.218771\n",
            "[47]\tvalidation_0-merror:0.194971\tvalidation_1-merror:0.218603\n",
            "[48]\tvalidation_0-merror:0.193308\tvalidation_1-merror:0.217508\n",
            "[49]\tvalidation_0-merror:0.192593\tvalidation_1-merror:0.217508\n",
            "[50]\tvalidation_0-merror:0.191856\tvalidation_1-merror:0.21633\n",
            "[51]\tvalidation_0-merror:0.191372\tvalidation_1-merror:0.216667\n",
            "[52]\tvalidation_0-merror:0.190467\tvalidation_1-merror:0.216582\n",
            "[53]\tvalidation_0-merror:0.189941\tvalidation_1-merror:0.216246\n",
            "[54]\tvalidation_0-merror:0.189415\tvalidation_1-merror:0.21633\n",
            "[55]\tvalidation_0-merror:0.18891\tvalidation_1-merror:0.216077\n",
            "[56]\tvalidation_0-merror:0.188447\tvalidation_1-merror:0.215488\n",
            "[57]\tvalidation_0-merror:0.187689\tvalidation_1-merror:0.214899\n",
            "[58]\tvalidation_0-merror:0.18729\tvalidation_1-merror:0.215152\n",
            "[59]\tvalidation_0-merror:0.186848\tvalidation_1-merror:0.214899\n",
            "[60]\tvalidation_0-merror:0.186742\tvalidation_1-merror:0.214983\n",
            "[61]\tvalidation_0-merror:0.18588\tvalidation_1-merror:0.214057\n",
            "[62]\tvalidation_0-merror:0.185227\tvalidation_1-merror:0.2133\n",
            "[63]\tvalidation_0-merror:0.184322\tvalidation_1-merror:0.212121\n",
            "[64]\tvalidation_0-merror:0.18407\tvalidation_1-merror:0.212205\n",
            "[65]\tvalidation_0-merror:0.183733\tvalidation_1-merror:0.212205\n",
            "[66]\tvalidation_0-merror:0.183333\tvalidation_1-merror:0.21271\n",
            "[67]\tvalidation_0-merror:0.182765\tvalidation_1-merror:0.212542\n",
            "[68]\tvalidation_0-merror:0.182323\tvalidation_1-merror:0.21229\n",
            "[69]\tvalidation_0-merror:0.181524\tvalidation_1-merror:0.211448\n",
            "[70]\tvalidation_0-merror:0.180997\tvalidation_1-merror:0.211111\n",
            "[71]\tvalidation_0-merror:0.180492\tvalidation_1-merror:0.211195\n",
            "[72]\tvalidation_0-merror:0.180156\tvalidation_1-merror:0.210774\n",
            "[73]\tvalidation_0-merror:0.179861\tvalidation_1-merror:0.210438\n",
            "[74]\tvalidation_0-merror:0.179125\tvalidation_1-merror:0.210269\n",
            "[75]\tvalidation_0-merror:0.178683\tvalidation_1-merror:0.210354\n",
            "[76]\tvalidation_0-merror:0.178241\tvalidation_1-merror:0.209764\n",
            "[77]\tvalidation_0-merror:0.177694\tvalidation_1-merror:0.209259\n",
            "[78]\tvalidation_0-merror:0.177189\tvalidation_1-merror:0.209175\n",
            "[79]\tvalidation_0-merror:0.176768\tvalidation_1-merror:0.209091\n",
            "[80]\tvalidation_0-merror:0.176473\tvalidation_1-merror:0.209091\n",
            "[81]\tvalidation_0-merror:0.175779\tvalidation_1-merror:0.20867\n",
            "[82]\tvalidation_0-merror:0.175274\tvalidation_1-merror:0.208249\n",
            "[83]\tvalidation_0-merror:0.175295\tvalidation_1-merror:0.208502\n",
            "[84]\tvalidation_0-merror:0.174453\tvalidation_1-merror:0.207828\n",
            "[85]\tvalidation_0-merror:0.174011\tvalidation_1-merror:0.207576\n",
            "[86]\tvalidation_0-merror:0.173674\tvalidation_1-merror:0.207492\n",
            "[87]\tvalidation_0-merror:0.173359\tvalidation_1-merror:0.207744\n",
            "[88]\tvalidation_0-merror:0.172917\tvalidation_1-merror:0.207912\n",
            "[89]\tvalidation_0-merror:0.173064\tvalidation_1-merror:0.207744\n",
            "[90]\tvalidation_0-merror:0.172517\tvalidation_1-merror:0.207828\n",
            "[91]\tvalidation_0-merror:0.171738\tvalidation_1-merror:0.207323\n",
            "[92]\tvalidation_0-merror:0.171633\tvalidation_1-merror:0.207155\n",
            "[93]\tvalidation_0-merror:0.171402\tvalidation_1-merror:0.207323\n",
            "[94]\tvalidation_0-merror:0.171044\tvalidation_1-merror:0.207828\n",
            "[95]\tvalidation_0-merror:0.170749\tvalidation_1-merror:0.207828\n",
            "[96]\tvalidation_0-merror:0.170476\tvalidation_1-merror:0.208081\n",
            "[97]\tvalidation_0-merror:0.170412\tvalidation_1-merror:0.207576\n",
            "[98]\tvalidation_0-merror:0.169823\tvalidation_1-merror:0.207323\n",
            "[99]\tvalidation_0-merror:0.169613\tvalidation_1-merror:0.207239\n",
            "[100]\tvalidation_0-merror:0.169129\tvalidation_1-merror:0.206734\n",
            "[101]\tvalidation_0-merror:0.169003\tvalidation_1-merror:0.206902\n",
            "[102]\tvalidation_0-merror:0.168729\tvalidation_1-merror:0.206566\n",
            "[103]\tvalidation_0-merror:0.167908\tvalidation_1-merror:0.206061\n",
            "[104]\tvalidation_0-merror:0.167551\tvalidation_1-merror:0.205808\n",
            "[105]\tvalidation_0-merror:0.167319\tvalidation_1-merror:0.205724\n",
            "[106]\tvalidation_0-merror:0.166961\tvalidation_1-merror:0.206229\n",
            "[107]\tvalidation_0-merror:0.166288\tvalidation_1-merror:0.20564\n",
            "[108]\tvalidation_0-merror:0.165614\tvalidation_1-merror:0.205724\n",
            "[109]\tvalidation_0-merror:0.165236\tvalidation_1-merror:0.205808\n",
            "[110]\tvalidation_0-merror:0.164878\tvalidation_1-merror:0.205808\n",
            "[111]\tvalidation_0-merror:0.164394\tvalidation_1-merror:0.20564\n",
            "[112]\tvalidation_0-merror:0.164183\tvalidation_1-merror:0.205892\n",
            "[113]\tvalidation_0-merror:0.163594\tvalidation_1-merror:0.205976\n",
            "[114]\tvalidation_0-merror:0.163615\tvalidation_1-merror:0.205892\n",
            "[115]\tvalidation_0-merror:0.163321\tvalidation_1-merror:0.20564\n",
            "[116]\tvalidation_0-merror:0.162837\tvalidation_1-merror:0.205556\n",
            "[117]\tvalidation_0-merror:0.162984\tvalidation_1-merror:0.205724\n",
            "[118]\tvalidation_0-merror:0.162668\tvalidation_1-merror:0.205556\n",
            "[119]\tvalidation_0-merror:0.162226\tvalidation_1-merror:0.205387\n",
            "[120]\tvalidation_0-merror:0.161574\tvalidation_1-merror:0.205724\n",
            "[121]\tvalidation_0-merror:0.161048\tvalidation_1-merror:0.205724\n",
            "[122]\tvalidation_0-merror:0.161027\tvalidation_1-merror:0.205724\n",
            "[123]\tvalidation_0-merror:0.160838\tvalidation_1-merror:0.205724\n",
            "[124]\tvalidation_0-merror:0.160122\tvalidation_1-merror:0.205219\n",
            "[125]\tvalidation_0-merror:0.15968\tvalidation_1-merror:0.204966\n",
            "[126]\tvalidation_0-merror:0.159596\tvalidation_1-merror:0.20505\n",
            "[127]\tvalidation_0-merror:0.159007\tvalidation_1-merror:0.205303\n",
            "[128]\tvalidation_0-merror:0.158754\tvalidation_1-merror:0.205387\n",
            "[129]\tvalidation_0-merror:0.15846\tvalidation_1-merror:0.20505\n",
            "[130]\tvalidation_0-merror:0.158039\tvalidation_1-merror:0.204882\n",
            "[131]\tvalidation_0-merror:0.157702\tvalidation_1-merror:0.20505\n",
            "[132]\tvalidation_0-merror:0.157449\tvalidation_1-merror:0.204966\n",
            "[133]\tvalidation_0-merror:0.157281\tvalidation_1-merror:0.205471\n",
            "[134]\tvalidation_0-merror:0.156881\tvalidation_1-merror:0.205471\n",
            "[135]\tvalidation_0-merror:0.156734\tvalidation_1-merror:0.205387\n",
            "[136]\tvalidation_0-merror:0.15646\tvalidation_1-merror:0.205135\n",
            "[137]\tvalidation_0-merror:0.156376\tvalidation_1-merror:0.205219\n",
            "[138]\tvalidation_0-merror:0.155787\tvalidation_1-merror:0.204798\n",
            "[139]\tvalidation_0-merror:0.155619\tvalidation_1-merror:0.205556\n",
            "[140]\tvalidation_0-merror:0.15484\tvalidation_1-merror:0.205724\n",
            "[141]\tvalidation_0-merror:0.154672\tvalidation_1-merror:0.205724\n",
            "[142]\tvalidation_0-merror:0.154609\tvalidation_1-merror:0.20564\n",
            "[143]\tvalidation_0-merror:0.154356\tvalidation_1-merror:0.205471\n",
            "[144]\tvalidation_0-merror:0.154019\tvalidation_1-merror:0.20564\n",
            "[145]\tvalidation_0-merror:0.153367\tvalidation_1-merror:0.205471\n",
            "[146]\tvalidation_0-merror:0.152925\tvalidation_1-merror:0.205471\n",
            "[147]\tvalidation_0-merror:0.152757\tvalidation_1-merror:0.205387\n",
            "[148]\tvalidation_0-merror:0.152525\tvalidation_1-merror:0.205135\n",
            "[149]\tvalidation_0-merror:0.152378\tvalidation_1-merror:0.205387\n",
            "[150]\tvalidation_0-merror:0.152231\tvalidation_1-merror:0.205471\n",
            "[151]\tvalidation_0-merror:0.151915\tvalidation_1-merror:0.205556\n",
            "[152]\tvalidation_0-merror:0.151452\tvalidation_1-merror:0.205303\n",
            "[153]\tvalidation_0-merror:0.151094\tvalidation_1-merror:0.204714\n",
            "[154]\tvalidation_0-merror:0.150842\tvalidation_1-merror:0.204377\n",
            "[155]\tvalidation_0-merror:0.150358\tvalidation_1-merror:0.204209\n",
            "[156]\tvalidation_0-merror:0.150231\tvalidation_1-merror:0.203956\n",
            "[157]\tvalidation_0-merror:0.149705\tvalidation_1-merror:0.203535\n",
            "[158]\tvalidation_0-merror:0.149411\tvalidation_1-merror:0.203367\n",
            "[159]\tvalidation_0-merror:0.149369\tvalidation_1-merror:0.203367\n",
            "[160]\tvalidation_0-merror:0.149032\tvalidation_1-merror:0.203199\n",
            "[161]\tvalidation_0-merror:0.148758\tvalidation_1-merror:0.203283\n",
            "[162]\tvalidation_0-merror:0.148464\tvalidation_1-merror:0.203451\n",
            "[163]\tvalidation_0-merror:0.147917\tvalidation_1-merror:0.203199\n",
            "[164]\tvalidation_0-merror:0.147496\tvalidation_1-merror:0.20362\n",
            "[165]\tvalidation_0-merror:0.147096\tvalidation_1-merror:0.20362\n",
            "[166]\tvalidation_0-merror:0.147117\tvalidation_1-merror:0.203872\n",
            "[167]\tvalidation_0-merror:0.146338\tvalidation_1-merror:0.203199\n",
            "[168]\tvalidation_0-merror:0.146044\tvalidation_1-merror:0.203283\n",
            "[169]\tvalidation_0-merror:0.145749\tvalidation_1-merror:0.203367\n",
            "[170]\tvalidation_0-merror:0.145581\tvalidation_1-merror:0.203367\n",
            "[171]\tvalidation_0-merror:0.14516\tvalidation_1-merror:0.202441\n",
            "[172]\tvalidation_0-merror:0.145244\tvalidation_1-merror:0.202189\n",
            "[173]\tvalidation_0-merror:0.144992\tvalidation_1-merror:0.202778\n",
            "[174]\tvalidation_0-merror:0.144634\tvalidation_1-merror:0.202441\n",
            "[175]\tvalidation_0-merror:0.144318\tvalidation_1-merror:0.202525\n",
            "[176]\tvalidation_0-merror:0.144024\tvalidation_1-merror:0.202609\n",
            "[177]\tvalidation_0-merror:0.143476\tvalidation_1-merror:0.202862\n",
            "[178]\tvalidation_0-merror:0.14314\tvalidation_1-merror:0.20303\n",
            "[179]\tvalidation_0-merror:0.142698\tvalidation_1-merror:0.203199\n",
            "[180]\tvalidation_0-merror:0.142529\tvalidation_1-merror:0.202862\n",
            "[181]\tvalidation_0-merror:0.142045\tvalidation_1-merror:0.202525\n",
            "[182]\tvalidation_0-merror:0.141793\tvalidation_1-merror:0.201515\n",
            "[183]\tvalidation_0-merror:0.141519\tvalidation_1-merror:0.201684\n",
            "[184]\tvalidation_0-merror:0.141519\tvalidation_1-merror:0.201768\n",
            "[185]\tvalidation_0-merror:0.141309\tvalidation_1-merror:0.201852\n",
            "[186]\tvalidation_0-merror:0.140909\tvalidation_1-merror:0.201852\n",
            "[187]\tvalidation_0-merror:0.140614\tvalidation_1-merror:0.201515\n",
            "[188]\tvalidation_0-merror:0.140488\tvalidation_1-merror:0.201599\n",
            "[189]\tvalidation_0-merror:0.140278\tvalidation_1-merror:0.202273\n",
            "[190]\tvalidation_0-merror:0.13992\tvalidation_1-merror:0.202357\n",
            "[191]\tvalidation_0-merror:0.139646\tvalidation_1-merror:0.202441\n",
            "[192]\tvalidation_0-merror:0.139478\tvalidation_1-merror:0.202189\n",
            "[193]\tvalidation_0-merror:0.139373\tvalidation_1-merror:0.202441\n",
            "[194]\tvalidation_0-merror:0.139099\tvalidation_1-merror:0.20202\n",
            "[195]\tvalidation_0-merror:0.13912\tvalidation_1-merror:0.202104\n",
            "[196]\tvalidation_0-merror:0.1387\tvalidation_1-merror:0.201936\n",
            "[197]\tvalidation_0-merror:0.138594\tvalidation_1-merror:0.202104\n",
            "[198]\tvalidation_0-merror:0.137984\tvalidation_1-merror:0.201684\n",
            "[199]\tvalidation_0-merror:0.137921\tvalidation_1-merror:0.201852\n",
            "[200]\tvalidation_0-merror:0.137668\tvalidation_1-merror:0.202273\n",
            "[201]\tvalidation_0-merror:0.137563\tvalidation_1-merror:0.202189\n",
            "[202]\tvalidation_0-merror:0.137205\tvalidation_1-merror:0.202104\n",
            "[203]\tvalidation_0-merror:0.136932\tvalidation_1-merror:0.202694\n",
            "[204]\tvalidation_0-merror:0.136721\tvalidation_1-merror:0.202609\n",
            "[205]\tvalidation_0-merror:0.136406\tvalidation_1-merror:0.202525\n",
            "[206]\tvalidation_0-merror:0.136069\tvalidation_1-merror:0.202189\n",
            "[207]\tvalidation_0-merror:0.13548\tvalidation_1-merror:0.202273\n",
            "[208]\tvalidation_0-merror:0.135227\tvalidation_1-merror:0.202946\n",
            "[209]\tvalidation_0-merror:0.13508\tvalidation_1-merror:0.203283\n",
            "[210]\tvalidation_0-merror:0.134407\tvalidation_1-merror:0.203199\n",
            "[211]\tvalidation_0-merror:0.134091\tvalidation_1-merror:0.203283\n",
            "[212]\tvalidation_0-merror:0.133965\tvalidation_1-merror:0.203199\n",
            "[213]\tvalidation_0-merror:0.133607\tvalidation_1-merror:0.202862\n",
            "[214]\tvalidation_0-merror:0.133375\tvalidation_1-merror:0.202778\n",
            "[215]\tvalidation_0-merror:0.133207\tvalidation_1-merror:0.202778\n",
            "[216]\tvalidation_0-merror:0.132933\tvalidation_1-merror:0.202189\n",
            "[217]\tvalidation_0-merror:0.132807\tvalidation_1-merror:0.202525\n",
            "[218]\tvalidation_0-merror:0.132702\tvalidation_1-merror:0.202357\n",
            "[219]\tvalidation_0-merror:0.132407\tvalidation_1-merror:0.20202\n",
            "[220]\tvalidation_0-merror:0.132134\tvalidation_1-merror:0.201936\n",
            "[221]\tvalidation_0-merror:0.132029\tvalidation_1-merror:0.201852\n",
            "[222]\tvalidation_0-merror:0.131692\tvalidation_1-merror:0.202273\n",
            "[223]\tvalidation_0-merror:0.131376\tvalidation_1-merror:0.202189\n",
            "[224]\tvalidation_0-merror:0.131334\tvalidation_1-merror:0.20202\n",
            "[225]\tvalidation_0-merror:0.130976\tvalidation_1-merror:0.201852\n",
            "[226]\tvalidation_0-merror:0.131019\tvalidation_1-merror:0.201936\n",
            "[227]\tvalidation_0-merror:0.130724\tvalidation_1-merror:0.201515\n",
            "[228]\tvalidation_0-merror:0.130492\tvalidation_1-merror:0.201178\n",
            "[229]\tvalidation_0-merror:0.130345\tvalidation_1-merror:0.201347\n",
            "[230]\tvalidation_0-merror:0.129945\tvalidation_1-merror:0.201599\n",
            "[231]\tvalidation_0-merror:0.12963\tvalidation_1-merror:0.20101\n",
            "[232]\tvalidation_0-merror:0.129082\tvalidation_1-merror:0.201431\n",
            "[233]\tvalidation_0-merror:0.128577\tvalidation_1-merror:0.201094\n",
            "[234]\tvalidation_0-merror:0.128114\tvalidation_1-merror:0.20101\n",
            "[235]\tvalidation_0-merror:0.127757\tvalidation_1-merror:0.201515\n",
            "[236]\tvalidation_0-merror:0.127483\tvalidation_1-merror:0.20101\n",
            "[237]\tvalidation_0-merror:0.126936\tvalidation_1-merror:0.200758\n",
            "[238]\tvalidation_0-merror:0.126684\tvalidation_1-merror:0.200842\n",
            "[239]\tvalidation_0-merror:0.126473\tvalidation_1-merror:0.200168\n",
            "[240]\tvalidation_0-merror:0.125989\tvalidation_1-merror:0.200421\n",
            "[241]\tvalidation_0-merror:0.125821\tvalidation_1-merror:0.200505\n",
            "[242]\tvalidation_0-merror:0.125337\tvalidation_1-merror:0.200926\n",
            "[243]\tvalidation_0-merror:0.124958\tvalidation_1-merror:0.200673\n",
            "[244]\tvalidation_0-merror:0.124811\tvalidation_1-merror:0.200842\n",
            "[245]\tvalidation_0-merror:0.124537\tvalidation_1-merror:0.200842\n",
            "[246]\tvalidation_0-merror:0.124495\tvalidation_1-merror:0.200673\n",
            "[247]\tvalidation_0-merror:0.124306\tvalidation_1-merror:0.200673\n",
            "[248]\tvalidation_0-merror:0.124116\tvalidation_1-merror:0.200421\n",
            "[249]\tvalidation_0-merror:0.124011\tvalidation_1-merror:0.200842\n",
            "[250]\tvalidation_0-merror:0.12359\tvalidation_1-merror:0.201263\n",
            "[251]\tvalidation_0-merror:0.123527\tvalidation_1-merror:0.201431\n",
            "[252]\tvalidation_0-merror:0.123338\tvalidation_1-merror:0.201431\n",
            "[253]\tvalidation_0-merror:0.12298\tvalidation_1-merror:0.201178\n",
            "[254]\tvalidation_0-merror:0.122559\tvalidation_1-merror:0.20101\n",
            "[255]\tvalidation_0-merror:0.122138\tvalidation_1-merror:0.200673\n",
            "[256]\tvalidation_0-merror:0.12197\tvalidation_1-merror:0.200589\n",
            "[257]\tvalidation_0-merror:0.121822\tvalidation_1-merror:0.200589\n",
            "[258]\tvalidation_0-merror:0.121738\tvalidation_1-merror:0.200589\n",
            "[259]\tvalidation_0-merror:0.12157\tvalidation_1-merror:0.200505\n",
            "[260]\tvalidation_0-merror:0.121402\tvalidation_1-merror:0.200505\n",
            "[261]\tvalidation_0-merror:0.120939\tvalidation_1-merror:0.2\n",
            "[262]\tvalidation_0-merror:0.120623\tvalidation_1-merror:0.2\n",
            "[263]\tvalidation_0-merror:0.120412\tvalidation_1-merror:0.200084\n",
            "[264]\tvalidation_0-merror:0.119928\tvalidation_1-merror:0.200168\n",
            "[265]\tvalidation_0-merror:0.119781\tvalidation_1-merror:0.2\n",
            "[266]\tvalidation_0-merror:0.119487\tvalidation_1-merror:0.199495\n",
            "[267]\tvalidation_0-merror:0.11915\tvalidation_1-merror:0.199663\n",
            "[268]\tvalidation_0-merror:0.118582\tvalidation_1-merror:0.200253\n",
            "[269]\tvalidation_0-merror:0.118455\tvalidation_1-merror:0.200168\n",
            "[270]\tvalidation_0-merror:0.117614\tvalidation_1-merror:0.199411\n",
            "[271]\tvalidation_0-merror:0.117445\tvalidation_1-merror:0.199327\n",
            "[272]\tvalidation_0-merror:0.117066\tvalidation_1-merror:0.199663\n",
            "[273]\tvalidation_0-merror:0.116856\tvalidation_1-merror:0.199327\n",
            "[274]\tvalidation_0-merror:0.116625\tvalidation_1-merror:0.198737\n",
            "[275]\tvalidation_0-merror:0.116393\tvalidation_1-merror:0.198906\n",
            "[276]\tvalidation_0-merror:0.116288\tvalidation_1-merror:0.19899\n",
            "[277]\tvalidation_0-merror:0.115909\tvalidation_1-merror:0.199074\n",
            "[278]\tvalidation_0-merror:0.115804\tvalidation_1-merror:0.199158\n",
            "[279]\tvalidation_0-merror:0.115383\tvalidation_1-merror:0.19899\n",
            "[280]\tvalidation_0-merror:0.115004\tvalidation_1-merror:0.199327\n",
            "[281]\tvalidation_0-merror:0.114689\tvalidation_1-merror:0.19899\n",
            "[282]\tvalidation_0-merror:0.114478\tvalidation_1-merror:0.199074\n",
            "[283]\tvalidation_0-merror:0.114205\tvalidation_1-merror:0.199074\n",
            "[284]\tvalidation_0-merror:0.114141\tvalidation_1-merror:0.199832\n",
            "[285]\tvalidation_0-merror:0.113742\tvalidation_1-merror:0.200084\n",
            "[286]\tvalidation_0-merror:0.113678\tvalidation_1-merror:0.199916\n",
            "[287]\tvalidation_0-merror:0.113468\tvalidation_1-merror:0.199663\n",
            "[288]\tvalidation_0-merror:0.113047\tvalidation_1-merror:0.199327\n",
            "[289]\tvalidation_0-merror:0.113068\tvalidation_1-merror:0.199327\n",
            "[290]\tvalidation_0-merror:0.112774\tvalidation_1-merror:0.199411\n",
            "[291]\tvalidation_0-merror:0.112374\tvalidation_1-merror:0.199074\n",
            "[292]\tvalidation_0-merror:0.112079\tvalidation_1-merror:0.199327\n",
            "[293]\tvalidation_0-merror:0.11189\tvalidation_1-merror:0.19899\n",
            "[294]\tvalidation_0-merror:0.111785\tvalidation_1-merror:0.198737\n",
            "[295]\tvalidation_0-merror:0.111301\tvalidation_1-merror:0.198485\n",
            "[296]\tvalidation_0-merror:0.110838\tvalidation_1-merror:0.199158\n",
            "[297]\tvalidation_0-merror:0.110753\tvalidation_1-merror:0.199579\n",
            "[298]\tvalidation_0-merror:0.110669\tvalidation_1-merror:0.199411\n",
            "[299]\tvalidation_0-merror:0.110501\tvalidation_1-merror:0.199663\n",
            "[300]\tvalidation_0-merror:0.110438\tvalidation_1-merror:0.199495\n",
            "[301]\tvalidation_0-merror:0.110354\tvalidation_1-merror:0.199158\n",
            "[302]\tvalidation_0-merror:0.110185\tvalidation_1-merror:0.198906\n",
            "[303]\tvalidation_0-merror:0.110143\tvalidation_1-merror:0.198906\n",
            "[304]\tvalidation_0-merror:0.109975\tvalidation_1-merror:0.198653\n",
            "[305]\tvalidation_0-merror:0.109659\tvalidation_1-merror:0.198485\n",
            "[306]\tvalidation_0-merror:0.109449\tvalidation_1-merror:0.198737\n",
            "[307]\tvalidation_0-merror:0.108902\tvalidation_1-merror:0.19899\n",
            "[308]\tvalidation_0-merror:0.10867\tvalidation_1-merror:0.198485\n",
            "[309]\tvalidation_0-merror:0.108565\tvalidation_1-merror:0.198569\n",
            "[310]\tvalidation_0-merror:0.108375\tvalidation_1-merror:0.198485\n",
            "[311]\tvalidation_0-merror:0.10787\tvalidation_1-merror:0.198401\n",
            "[312]\tvalidation_0-merror:0.107828\tvalidation_1-merror:0.198316\n",
            "[313]\tvalidation_0-merror:0.107639\tvalidation_1-merror:0.197727\n",
            "[314]\tvalidation_0-merror:0.107597\tvalidation_1-merror:0.197559\n",
            "[315]\tvalidation_0-merror:0.107407\tvalidation_1-merror:0.198064\n",
            "[316]\tvalidation_0-merror:0.107281\tvalidation_1-merror:0.198232\n",
            "[317]\tvalidation_0-merror:0.106965\tvalidation_1-merror:0.198064\n",
            "[318]\tvalidation_0-merror:0.106734\tvalidation_1-merror:0.198316\n",
            "[319]\tvalidation_0-merror:0.106524\tvalidation_1-merror:0.197896\n",
            "[320]\tvalidation_0-merror:0.106229\tvalidation_1-merror:0.197896\n",
            "[321]\tvalidation_0-merror:0.106145\tvalidation_1-merror:0.197391\n",
            "[322]\tvalidation_0-merror:0.105976\tvalidation_1-merror:0.197306\n",
            "[323]\tvalidation_0-merror:0.105787\tvalidation_1-merror:0.197475\n",
            "[324]\tvalidation_0-merror:0.105408\tvalidation_1-merror:0.197559\n",
            "[325]\tvalidation_0-merror:0.105387\tvalidation_1-merror:0.197559\n",
            "[326]\tvalidation_0-merror:0.105219\tvalidation_1-merror:0.197559\n",
            "[327]\tvalidation_0-merror:0.105008\tvalidation_1-merror:0.197896\n",
            "[328]\tvalidation_0-merror:0.10484\tvalidation_1-merror:0.197811\n",
            "[329]\tvalidation_0-merror:0.104714\tvalidation_1-merror:0.198064\n",
            "[330]\tvalidation_0-merror:0.104482\tvalidation_1-merror:0.197896\n",
            "[331]\tvalidation_0-merror:0.104019\tvalidation_1-merror:0.197727\n",
            "[332]\tvalidation_0-merror:0.103914\tvalidation_1-merror:0.197643\n",
            "[333]\tvalidation_0-merror:0.103683\tvalidation_1-merror:0.197727\n",
            "[334]\tvalidation_0-merror:0.103641\tvalidation_1-merror:0.197811\n",
            "[335]\tvalidation_0-merror:0.103367\tvalidation_1-merror:0.197896\n",
            "[336]\tvalidation_0-merror:0.10303\tvalidation_1-merror:0.198148\n",
            "[337]\tvalidation_0-merror:0.102694\tvalidation_1-merror:0.197896\n",
            "[338]\tvalidation_0-merror:0.102673\tvalidation_1-merror:0.197727\n",
            "[339]\tvalidation_0-merror:0.102315\tvalidation_1-merror:0.197811\n",
            "[340]\tvalidation_0-merror:0.102062\tvalidation_1-merror:0.197727\n",
            "[341]\tvalidation_0-merror:0.101957\tvalidation_1-merror:0.197896\n",
            "[342]\tvalidation_0-merror:0.101726\tvalidation_1-merror:0.197811\n",
            "[343]\tvalidation_0-merror:0.101368\tvalidation_1-merror:0.19798\n",
            "[344]\tvalidation_0-merror:0.101221\tvalidation_1-merror:0.197896\n",
            "[345]\tvalidation_0-merror:0.101031\tvalidation_1-merror:0.197727\n",
            "[346]\tvalidation_0-merror:0.100737\tvalidation_1-merror:0.197727\n",
            "[347]\tvalidation_0-merror:0.100568\tvalidation_1-merror:0.197811\n",
            "[348]\tvalidation_0-merror:0.100421\tvalidation_1-merror:0.198064\n",
            "[349]\tvalidation_0-merror:0.100337\tvalidation_1-merror:0.197896\n",
            "[350]\tvalidation_0-merror:0.100147\tvalidation_1-merror:0.197896\n",
            "[351]\tvalidation_0-merror:0.1\tvalidation_1-merror:0.197811\n",
            "[352]\tvalidation_0-merror:0.09979\tvalidation_1-merror:0.197811\n",
            "[353]\tvalidation_0-merror:0.099537\tvalidation_1-merror:0.197727\n",
            "[354]\tvalidation_0-merror:0.099474\tvalidation_1-merror:0.197391\n",
            "[355]\tvalidation_0-merror:0.09939\tvalidation_1-merror:0.197559\n",
            "[356]\tvalidation_0-merror:0.099263\tvalidation_1-merror:0.197643\n",
            "[357]\tvalidation_0-merror:0.099053\tvalidation_1-merror:0.197391\n",
            "[358]\tvalidation_0-merror:0.098611\tvalidation_1-merror:0.197727\n",
            "[359]\tvalidation_0-merror:0.098316\tvalidation_1-merror:0.197222\n",
            "[360]\tvalidation_0-merror:0.098274\tvalidation_1-merror:0.197559\n",
            "[361]\tvalidation_0-merror:0.098148\tvalidation_1-merror:0.197559\n",
            "[362]\tvalidation_0-merror:0.098106\tvalidation_1-merror:0.197391\n",
            "[363]\tvalidation_0-merror:0.097959\tvalidation_1-merror:0.197306\n",
            "[364]\tvalidation_0-merror:0.097811\tvalidation_1-merror:0.197222\n",
            "[365]\tvalidation_0-merror:0.097643\tvalidation_1-merror:0.197727\n",
            "[366]\tvalidation_0-merror:0.097285\tvalidation_1-merror:0.197306\n",
            "[367]\tvalidation_0-merror:0.096949\tvalidation_1-merror:0.197475\n",
            "[368]\tvalidation_0-merror:0.096717\tvalidation_1-merror:0.197306\n",
            "[369]\tvalidation_0-merror:0.096528\tvalidation_1-merror:0.197559\n",
            "[370]\tvalidation_0-merror:0.096254\tvalidation_1-merror:0.19697\n",
            "[371]\tvalidation_0-merror:0.096023\tvalidation_1-merror:0.197138\n",
            "[372]\tvalidation_0-merror:0.09577\tvalidation_1-merror:0.197138\n",
            "[373]\tvalidation_0-merror:0.095602\tvalidation_1-merror:0.197054\n",
            "[374]\tvalidation_0-merror:0.095391\tvalidation_1-merror:0.197222\n",
            "[375]\tvalidation_0-merror:0.095139\tvalidation_1-merror:0.197306\n",
            "[376]\tvalidation_0-merror:0.094718\tvalidation_1-merror:0.197222\n",
            "[377]\tvalidation_0-merror:0.094592\tvalidation_1-merror:0.197306\n",
            "[378]\tvalidation_0-merror:0.094381\tvalidation_1-merror:0.19697\n",
            "[379]\tvalidation_0-merror:0.094381\tvalidation_1-merror:0.197054\n",
            "[380]\tvalidation_0-merror:0.094066\tvalidation_1-merror:0.197391\n",
            "[381]\tvalidation_0-merror:0.094045\tvalidation_1-merror:0.197391\n",
            "[382]\tvalidation_0-merror:0.093918\tvalidation_1-merror:0.197222\n",
            "[383]\tvalidation_0-merror:0.093855\tvalidation_1-merror:0.197222\n",
            "[384]\tvalidation_0-merror:0.093792\tvalidation_1-merror:0.19697\n",
            "[385]\tvalidation_0-merror:0.093687\tvalidation_1-merror:0.197475\n",
            "[386]\tvalidation_0-merror:0.093455\tvalidation_1-merror:0.197643\n",
            "[387]\tvalidation_0-merror:0.093287\tvalidation_1-merror:0.197811\n",
            "[388]\tvalidation_0-merror:0.093203\tvalidation_1-merror:0.197643\n",
            "[389]\tvalidation_0-merror:0.093098\tvalidation_1-merror:0.197727\n",
            "[390]\tvalidation_0-merror:0.092887\tvalidation_1-merror:0.197896\n",
            "[391]\tvalidation_0-merror:0.092656\tvalidation_1-merror:0.197811\n",
            "[392]\tvalidation_0-merror:0.092361\tvalidation_1-merror:0.197811\n",
            "[393]\tvalidation_0-merror:0.091982\tvalidation_1-merror:0.197306\n",
            "[394]\tvalidation_0-merror:0.091814\tvalidation_1-merror:0.197559\n",
            "[395]\tvalidation_0-merror:0.091625\tvalidation_1-merror:0.197391\n",
            "[396]\tvalidation_0-merror:0.091435\tvalidation_1-merror:0.197559\n",
            "[397]\tvalidation_0-merror:0.091372\tvalidation_1-merror:0.197643\n",
            "[398]\tvalidation_0-merror:0.091098\tvalidation_1-merror:0.197727\n",
            "[399]\tvalidation_0-merror:0.090972\tvalidation_1-merror:0.197643\n",
            "[400]\tvalidation_0-merror:0.090741\tvalidation_1-merror:0.197896\n",
            "[401]\tvalidation_0-merror:0.090446\tvalidation_1-merror:0.19798\n",
            "[402]\tvalidation_0-merror:0.090194\tvalidation_1-merror:0.19798\n",
            "[403]\tvalidation_0-merror:0.090173\tvalidation_1-merror:0.198401\n",
            "[404]\tvalidation_0-merror:0.089878\tvalidation_1-merror:0.198148\n",
            "[405]\tvalidation_0-merror:0.089541\tvalidation_1-merror:0.197811\n",
            "[406]\tvalidation_0-merror:0.089268\tvalidation_1-merror:0.197811\n",
            "[407]\tvalidation_0-merror:0.089057\tvalidation_1-merror:0.197896\n",
            "[408]\tvalidation_0-merror:0.088889\tvalidation_1-merror:0.198064\n",
            "[409]\tvalidation_0-merror:0.089015\tvalidation_1-merror:0.197811\n",
            "[410]\tvalidation_0-merror:0.088868\tvalidation_1-merror:0.197896\n",
            "[411]\tvalidation_0-merror:0.088742\tvalidation_1-merror:0.197727\n",
            "[412]\tvalidation_0-merror:0.088384\tvalidation_1-merror:0.19798\n",
            "[413]\tvalidation_0-merror:0.0883\tvalidation_1-merror:0.198064\n",
            "[414]\tvalidation_0-merror:0.08811\tvalidation_1-merror:0.197811\n",
            "[415]\tvalidation_0-merror:0.088026\tvalidation_1-merror:0.19798\n",
            "[416]\tvalidation_0-merror:0.087837\tvalidation_1-merror:0.197727\n",
            "[417]\tvalidation_0-merror:0.087816\tvalidation_1-merror:0.197727\n",
            "[418]\tvalidation_0-merror:0.087753\tvalidation_1-merror:0.197643\n",
            "[419]\tvalidation_0-merror:0.087584\tvalidation_1-merror:0.197811\n",
            "[420]\tvalidation_0-merror:0.087184\tvalidation_1-merror:0.198064\n",
            "Stopping. Best iteration:\n",
            "[370]\tvalidation_0-merror:0.096254\tvalidation_1-merror:0.19697\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
              "              colsample_bynode=1, colsample_bytree=1, gamma=0,\n",
              "              learning_rate=0.1, max_delta_step=0, max_depth=7,\n",
              "              min_child_weight=1, missing=None, n_estimators=1000, n_jobs=-1,\n",
              "              nthread=None, objective='multi:softprob', random_state=0,\n",
              "              reg_alpha=0, reg_lambda=1, scale_pos_weight=1, seed=None,\n",
              "              silent=None, subsample=1, verbosity=1)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 51
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vWCdNkxlUle7",
        "colab_type": "code",
        "outputId": "ed8bbae4-151d-4b12-a6e1-92baa1686cc8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 284
        }
      },
      "source": [
        "results = model.evals_result()\n",
        "train_error = results['validation_0']['merror']\n",
        "val_error = results['validation_1']['merror']\n",
        "epoch = range(1, len(train_error)+1)\n",
        "plt.plot(epoch, train_error, label='Train')\n",
        "plt.plot(epoch, val_error, label='Validation')\n",
        "plt.ylabel('Classification Error')\n",
        "plt.xlabel('Model Complexity (n_estimators)')\n",
        "# plt.ylim((0.18, 0.22))  # Zoom in\n",
        "plt.legend();"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAZIAAAELCAYAAADz6wBxAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDMuMC4zLCBo\ndHRwOi8vbWF0cGxvdGxpYi5vcmcvnQurowAAIABJREFUeJzs3Xd4leX5wPHvnQ0ZhAxWAiTsPSND\nZIkDsYpaHChuxbqrrVU71Z+2trUWtWpdOOrArbhFBEGUEfbeK2GFlQAJI8n9++N5g4cYkkDOyUng\n/lzXuTjv845zn9f23HnG+zyiqhhjjDHHKyTYARhjjKndLJEYY4ypEkskxhhjqsQSiTHGmCqxRGKM\nMaZKLJEYY4ypEkskxhhjqsQSiTHGmCqxRGKMMaZKwoIdQHVISkrStLS0YIdhjDG1yuzZs7eranJF\nx50UiSQtLY3MzMxgh2GMMbWKiKyvzHHWtGWMMaZKLJEYY4ypEkskxhhjquSk6CMxxpwYDh06RFZW\nFvv37w92KCeUqKgoUlNTCQ8PP67zLZEYY2qNrKwsYmNjSUtLQ0SCHc4JQVXZsWMHWVlZpKenH9c1\nrGnLGFNr7N+/n8TEREsifiQiJCYmVqmWZ4nEGFOrWBLxv6reU0skFSkugmWfQXFxsCMxxpgayRJJ\nRRa+C+Muh2WfBjsSY0yQ7dixg27dutGtWzcaNWpESkrK4e2DBw9W6hrXXnsty5cvD3Ck1cs62ysy\n/y3378qvocP5wY3FGBNUiYmJzJs3D4AHHniAmJgYfvvb3x5xjKqiqoSElP13+ssvvxzwOKub1UjK\nk5sFa76DkDCXSA7sDXZExpgaaNWqVXTo0IErrriCjh07snnzZkaPHk1GRgYdO3bkoYceOnzsaaed\nxrx58ygsLCQ+Pp777ruPrl270rdvX7Zt2xbEb3H8rEZSngXvAArnPQnjb4OJD8GwfwQ7KmMM8OAn\ni1myKc+v1+zQJI6/nNfxuM5dtmwZr732GhkZGQA8+uijJCQkUFhYyODBgxkxYgQdOnQ44pzc3FwG\nDhzIo48+yt13383YsWO57777qvw9qpvVSMqzdgo06wvdr4CWQ2D9D8GOyBhTQ7Vs2fJwEgF46623\n6NGjBz169GDp0qUsWbLkZ+fUqVOHc845B4CePXuybt266grXr6xGUp5RH0D+dvc+uS2s+96N3jpK\n26cxpvocb80hUKKjow+/X7lyJU888QQzZ84kPj6eUaNGlfmcRkRExOH3oaGhFBYWVkus/ma/iOUJ\nCYGYBu59UmsoLIC8rODGZIyp8fLy8oiNjSUuLo7Nmzfz1VdfBTukgLIaSWUltnb/bl8B8c2CG4sx\npkbr0aMHHTp0oF27djRv3px+/foFO6SAElUNdgwBl5GRoVVe2GpvDjzWCs7+G/S9xT+BGWOOydKl\nS2nfvn2wwzghlXVvRWS2qmYc5ZTDrGmrsmKSIToZti4OdiTGGFOjWCI5Fg07wdaFwY7CGGNqFEsk\nx6JRJ9i2FIoOBTsSY4ypMSyRHItGXaHoIGxdFOxIjDGmxghoIhGRoSKyXERWicjPHtcUkbtFZImI\nLBCRiSLS3GdfkYjM817jfcrTRWSGd823RSSi9HX9aXNuAXe9PY8dew9Ai0GAwMoJgfxIY4ypVQKW\nSEQkFHgaOAfoAIwUkQ6lDpsLZKhqF+A9wHf+kQJV7ea9fGdL/Dvwb1VtBewCrg/Ud9h/qIibX5/D\nh3OzeTtzo+twT+kJK74M1EcaY0ytE8gaSS9glaquUdWDwDhguO8BqjpJVfO9zelAankXFLf6yum4\npAPwKnCBX6P+KTaue2UW8zbuBmD8vE3sP1QELQbCpnlwqCAQH2uMqcEGDx78s4cLx4wZw80333zU\nc2JiYgDYtGkTI0aMKPOYQYMGUdEjCmPGjCE/P//w9rBhw9i9e3dlQw+oQCaSFGCjz3aWV3Y01wNf\n+GxHiUimiEwXkZJkkQjsVtWSeQQquuZxExFuHNCCl689hccu7sqyLXt4YPxiVyPRIti8IBAfa4yp\nwUaOHMm4ceOOKBs3bhwjR46s8NwmTZrw3nvvVXjc0ZROJJ9//jnx8fHHfT1/qhGd7SIyCsgA/ulT\n3Nx7EOZyYIyItDzGa472ElFmTk7OccU1uG0DBrdtwIieqZzVoSEz1u6EJj3czuzZx3VNY0ztNWLE\nCD777LPDi1itW7eOTZs20b17d4YMGUKPHj3o3LkzH3/88c/OXbduHZ06dQKgoKCAyy67jPbt23Ph\nhRdSUPBTC8fNN998ePr5v/zlLwA8+eSTbNq0icGDBzN48GAA0tLS2L7dzQX4+OOP06lTJzp16sSY\nMWMOf1779u258cYb6dixI2edddYRn+NPgZwiJRto6rOd6pUdQUTOAP4ADFTVAyXlqprt/btGRCYD\n3YH3gXgRCfNqJWVe0zvveeB5cE+2V/XLtG8cx4SlW9lfpwFRCS3h+39D6zPdHFzGmOr3xX2wxc/P\ndTXqDOc8etTdCQkJ9OrViy+++ILhw4czbtw4LrnkEurUqcOHH35IXFwc27dvp0+fPpx//vlHXQv9\n2WefpW7duixdupQFCxbQo0ePw/seeeQREhISKCoqYsiQISxYsIA77riDxx9/nEmTJpGUlHTEtWbP\nns3LL7/MjBkzUFV69+7NwIEDqV+/PitXruStt97ihRde4JJLLuH9999n1KhR/rlXPgJZI5kFtPZG\nWUUAlwHjfQ8Qke7Ac8D5qrrNp7y+iER675OAfsASdfO5TAJKGhqvBn6e+gOgXaNYVGHl1r0w8i3Q\nYnhrJGxbVh0fb4ypIXybt0qatVSV3//+93Tp0oUzzjiD7Oxstm7detRrTJky5fAPepcuXejSpcvh\nfe+88w49evSge/fuLF68uMzp5319//33XHjhhURHRxMTE8NFF13E1KlTAUhPT6dbt25AYKepD1iN\nRFULReQ24CsgFBirqotF5CEgU1XH45qyYoB3vcy9wRuh1R54TkSKccnuUVUtuZv3AuNE5GHcqK+X\nAvUdfLVpFAvA0s15dD6lLVzyGrw9Cp7rD+f+C3pcVR1hGGNKlFNzCKThw4dz1113MWfOHPLz8+nZ\nsyevvPIKOTk5zJ49m/DwcNLS0sqcNr4ia9eu5bHHHmPWrFnUr1+fa6655riuUyIyMvLw+9DQ0IA1\nbQW0j0RVP1fVNqraUlUf8cr+7CURVPUMVW1Yepivqv6gqp1Vtav370s+11yjqr1UtZWqXuzbHBZI\n6YnRJMdGMmm5V3FK6we3zoS002D8HZA9pzrCMMYEWUxMDIMHD+a666473Mmem5tLgwYNCA8PZ9Kk\nSaxfv77cawwYMIA333wTgEWLFrFggRu8k5eXR3R0NPXq1WPr1q188cVP449iY2PZs2fPz67Vv39/\nPvroI/Lz89m3bx8ffvgh/fv399fXrZQa0dleG4SECGd3bMjk5TkUHCxyhTHJcPGrEBYFc18PboDG\nmGozcuRI5s+ffziRXHHFFWRmZtK5c2dee+012rVrV+75N998M3v37qV9+/b8+c9/pmfPngB07dqV\n7t27065dOy6//PIjpp8fPXo0Q4cOPdzZXqJHjx5cc8019OrVi969e3PDDTfQvXt3P3/j8tk08sfg\n22Vbue6VTMaN7kOfFok/7Xj/Blj+BVz5ITTtVeXPMcaUzaaRDxybRr6adE11Y7YXZJV6CGjIXyA6\nCT78FRQXBSEyY4wJHkskxyAxJpKU+DrMz8o9ckd8UzjzIdi5Gib9FTbMCE6AxhgTBJZIjlHXpvV+\nXiMBaHeeG4M+9TEYe5ZNoWJMgJwMzfHVrar31BLJMeqSGs/GnQXs3HfwyB0hIXDBsxBVz23/NQV2\nrq3+AI05gUVFRbFjxw5LJn6kquzYsYOoqKjjvkYgn2w/IXVJdYliQdZuBrVtcOTORp3hnjXweHvY\ntw2mPwPD/lnGVYwxxyM1NZWsrCyOd9ojU7aoqChSU8udM7dclkiOUeeUeojAvI1lJBKA0DC4bSaM\nvx0WvANn/h+EH3+mN8b8JDw8nPT09GCHYUqxpq1jFBsVzinNE3h52jo27T5KP0id+nDKDbB/Nyz7\ntHoDNMaYamaJ5Dj8fUQXCouK+fW4eRQXH6WtNm0AxDeHr/8Es160YcHGmBOWJZLjkJ4UzV/O68jM\ndTv5aF6Zkw+7zvdfvghxTeCz38B3f6/eII0xpppYIjlOI3qm0iW1Hg+MX8ySTXllH9S0F9zwDXQd\nCVP+CTkrqjdIY4ypBpZIjlNIiPD05T2IjgzjypdmsCX3KDN0isBZD0N4NEx8sHqDNMaYamCJpAqa\nJtTltet6kVtwiOemrD76gdFJ0O9O1/G+cWb1BWiMMdXAEkkVtW4Yy/BuKbw5YwOrtv18iufD+t4C\n0Q1gwl/AHqYyxpxALJH4wb3ntCU6Mow7x83jYGFx2QdFRMOge2HDD7D62+oN0BhjAsgSiR80iI3i\n0Ys6s3hTHq/+sO7oB3a/EmKbuIkdiwqrLT5jjAkkSyR+clbHRvRpkcDYaWs5UHiUZ0bCIuHMByE7\nE6aNqd4AjTEmQCyR+NGtg1uxOXc/v313wdEfVOxyCbQ+2z1Xsn1V9QZojDEBENBEIiJDRWS5iKwS\nkfvK2H+3iCwRkQUiMlFEmnvl3UTkRxFZ7O271OecV0RkrYjM817dAvkdjkX/1sncO7Qdn8zfxLPf\nlTOKq++tUHQQ/tMTsqq+cqMxxgRTwBKJiIQCTwPnAB2AkSLSodRhc4EMVe0CvAf8wyvPB65S1Y7A\nUGCMiMT7nHePqnbzXvMC9R2Ox68GtuDsjg15dvJqducfLPugFgPhqvEQ0xA+uBEO7K3eII0xxo8C\nWSPpBaxS1TWqehAYBwz3PUBVJ6lqvrc5HUj1yleo6krv/SZgG5AcwFj9RkS4+8y27D1QyEvfl7Me\nSYuBMGKsW7PkuQGwZVH1BWmMMX4UyESSAmz02c7yyo7meuCL0oUi0guIAHzbih7xmrz+LSKR/gjW\nn9o2iuXczo0Z+/1a1m3fd/QD006DK951qym+OAQ+uAlys6ovUGOM8YMa0dkuIqOADOCfpcobA/8D\nrlXVkgc07gfaAacACcC9R7nmaBHJFJHMYCyCc9857YgIC+G2t+ZQdLSOd4DWZ8KNE10n/MJ34d1r\nbaZgY0ytEshEkg009dlO9cqOICJnAH8AzlfVAz7lccBnwB9UdXpJuapuVucA8DKuCe1nVPV5Vc1Q\n1Yzk5OpvFWuaUJcHzu/Iouw8Xp5WwZK7cU3g/Kdg+NOQNdMNDbY1340xtUQgE8ksoLWIpItIBHAZ\nMN73ABHpDjyHSyLbfMojgA+B11T1vVLnNPb+FeACoMZ2LpzftQlntG/II58vZerKStSKulwKSW1h\n4kPw9R8DH6AxxvhBwBKJqhYCtwFfAUuBd1R1sYg8JCLne4f9E4gB3vWG8pYkmkuAAcA1ZQzzfUNE\nFgILgSTg4UB9h6oSEf5zeXdaJsdw73sL2H+ogiarkBC4+BUIi3KLYS211RWNMTWf6EkwgWBGRoZm\nZgbveY0fVm3n8hdn8H/DO3Jl37SKT1j2GYy73L0/5x9wyo0uyRhjTDUSkdmqmlHRcfbrVA36tkyk\na9N4Xp++oXIntDkHLnoBGnSEL34HH98KB8sZ/WWMMUFkiaQaiAgjeqSwfOselm05ymqKvkJC3Ciu\nX02FU++A+W/CM31gfyXONcaYamaJpJoM69yYyLAQnvhmZeVPCgmFMx+CC5+H3Rvg351gw4zABWmM\nMceh3EQiIiEicmp1BXMiS4yJ5PbTW/HFoi0szMqt/Iki0PVSNzT44F4YexaM6eKau77/N+RtClzQ\nxhhTCeUmEu8hwKerKZYT3pV904gIC+Hd2RsrPri07qNg5FsQ3xyS2sC8t+CbB+C/p8HqSa7GUnyU\nRbWMMSaAwipxzEQR+SXwgZ4MQ7wCqF6dcM5s35DPF27hwfM74h6FOQZtznYvcAtj7VwNb1wM/7vA\nO0Dggmeg2+V+jdsYY8pTmT6Sm4B3gYMikicie0TEen2P04A2SWzfe4DVOVWc8Tc0DJLbwvUTYNDv\n4fQ/QWxj+Pwe2LXeP8EaY0wlVJhIVDVWVUNUNVxV47ztuOoI7kTUp0UiAD+u3uGfC8Y2dGvBD/gt\nXP8VIK7/pLgY1nwH89+G/J3++SxjjClDZZq28J5EH+BtTlZVe+T6ODVLqEvL5Giem7KG4d1TiIsK\n99/F45vB0L/B+NvgX21gnzctS1gduPJDaN7Xf59ljDGeCmskIvIocCewxHvdKSJ/C3RgJyoR4R8j\nupK1q4CXplYwmePx6D4KznjALed7xgNw/TduUsg3RsCLZ8LMF1z/ijHG+EmFU6SIyAKgW8k07t7K\nh3O9VQ1rhWBPkVKWG17NJHP9TqbfP4So8NDAftiudfDtw7B5PmxfAbFNICYZBv8R2pwV2M82xtRa\n/p4ixXeZ23rHF5Lxdc2paezOP8Q3S7cG/sPqp8EvX4RbZ8Klr0Oz3rBvO7x1qVtMa+L/wZKPwQbl\nGWOOQ2X6SP4GzBWRSYDg+kruC2hUJ4G+LRNpGBfJ27M28osuTarnQ0Wg/XnudXAffHo3rP4W8reD\nFrsp7BNawHlPuE78A3vdOWFR7il7gIP5sG0pJLaAOvWrJ25jTI1WbtOWt+ZHKlCIW5EQYKaqbqmG\n2PymJjZtATw/ZTV//XwZY6/J4PR2DYMXSHERzH4Zvvsn7N0CdZPcQ4/ZmVB00HXWn/ZrN6x4/pvu\nnNgmcMr10O5caNA+eLEbYwKmsk1blekjWaiqnf0WWRDU1ERysLCYXzw1lV35h5hw1wDi60YEOyTI\nng0/POX6VZr1hchYWDsVNvwAEgLdrnBNZcs+g01z3DmRcdBrNAy6z00sWXwIYhsF81sYY/zAn4nk\nVeA/qjrLX8FVt5qaSAAWZefyi6e+556z23Lr4FbBDqdsqm4KlogYiE78qTw3G378D+xYBSu/hrgU\nKNgFoeHQYpDrhwkJcx38hwpcYor1al71UiF7jrt2nXgY/AeIToKNM90os6TW7lmYZZ+4cxNaQkI6\nbFsCc/7nmuJKklW9VIhOhvrp7mn/3CxI6QktBlb3nTLmhOLPRLIMaAWsB/bh+knURm35z6gXZ7By\n2x6+u2dw4EdwBcryL2HOa5CXDft3Q2iEayLL3wENO0JUHKz61iUagIN7ILEVhNeFHatdE1poOBzK\nB8QljbxNULj/558VFQ91E1zCKC50SaUsvW6CwfdbX44xx8mfiaR5WeWqWmvm4ajpiaRkBcU7hrTm\nrjNaH/scXLVNUaHri4lLcZ35O9fArJdcUkgfCFsXuSa26CRodio06wNZs2DzAtixEi58ziWSwgMg\noVCwE/Zuc306TXpAfFOY/CjM+C+EhEOrITDwXtfvExENe7aAFsH6H2DTPMi41iW1okMQVgOaF42p\nIfySSLxnRharajt/BlfdanoiAbjljdl8vnALV/dtzgPHM6Gj+bktC2HBO66mtH+3Kwuv69V6fIRG\nulpNSCiMGOua4xJautrQ6m9hxVcQHgUD7nFJrSyqLikeTXExbJzumgeT28L6afDFfa7GVnQImp7i\nkmjDDtC0N4RH2/LKJuj8WSP5GLhdVSu5TuwR5w4FngBCgRdV9dFS++8GbsCNCssBriup6YjI1cAf\nvUMfVtVXvfKewCtAHeBz4M6KZiWuDYmkuFh5+LOljJ22lv9c3r36hgSfDPbtgJVfuaayPVugfnP3\nA972XNecNu8NV1NZOcHVhkpr0AH2bnXnXPCsm8p/3zbXdLdvm3sOZ/cG13wXFgXN+7naVEQMhEXC\n8s/dyLgtC9z1ouLhQJ5LVs37ulrT0vE/TWkD7trdRrp966ZCYmto1AliGkKHC1zSkpDyk5cxVeTP\nRDIF6A7MxPWRAKCq51dwXiiwAjgTyAJmASNVdYnPMYOBGaqaLyI3A4NU9VIRSQAygQxAgdlAT1Xd\nJSIzgTuAGbhE8qSqflFeLLUhkQAUFSvnPfU9OXsP8Pkd/UmOjQx2SCeX3CzXJCYCDTq6p/9TerpR\nagf3wcvDYPO8n5/XqLMbXLBjNeRudMnKNymk9HSJpOMFbj60xR9BVD23+mXdBHeMKhzYA1Mfg/25\nbiDD6m9dE1zjrm47f7s7NrGV62sq2OUSTNNeboLOloOg+1VuOHZkDGxZ5EbQHSpwCSiuifuOEx+E\nrNkQ19gtOdDxItePZEnJlOLPRFLm0BdV/a6C8/oCD6jq2d72/d55Zc7TJSLdcaPD+onISFxSucnb\n9xww2XtNKmlqK33c0dSWRAKwbEsew/8zjTM6NOTpy3sEOxzja+daWPYpJLd3P8qb57tVK7te5oZJ\n+youdv05xYWuRnM8P9JFha5JLjrJJZq9W12/zo//cbWiDdNdzeZQ/pEDDkLCXX/QtsVlXzeqHrQ5\nx9W+SmpgIeGuVhYRDW2Guua1fdugXlO3Bs6M51zTX6/RrpZVHlXXp7U/D9L7V3y8qbEqm0iO+mS7\niLRT1WWq+p2IRKrqAZ99R2koPkIK4LsUYBbQu5zjrwdKahZlnZvivbLKKC8r/tHAaIBmzZpVItya\noV2jOEYPaMFT367ipgG76ZIaX/FJpnokpMOpt/+03bDD0Y8NCXF9IVURGuaSCLhEFNsIOl3kXuAS\nTUio62MJDXeDFlZ8BVP/5ZrZ+v3aNePFN3M1mh2rXO1kwD1uGLaqq2Gt+c4lrIP7XLLKfMm9yrLw\nXfe5LQa6Idu7N8CutW7gQ26Wqx0t+RimP+OOj4yD9l7jRXwzN9S7yyVucMSEP7uaW/5Ol6x6Xutq\nf+FRLpaQMEtCtcRRayQiMkdVe5R+X9b2Uc4fAQxV1Ru87SuB3qp6WxnHjgJuAwaq6gER+S0QpaoP\ne/v/BBTgaiSPquoZXnl/4F5V/UV5sdSmGgnAnv2HGPCPSXRoEscbN1QmZxvjR7vWu5pUnfqw4kv3\n8GnnEbBnK3z/uBuwsGst3pMAZV+j+yjXB7XgbVj7nTu2wFsXJzQSig64AQWJLSC6Aayd4prhwqIg\n9RTIynRDyNP6udpf/XToOtIl6OzZLplFJ0HqUf5YPlTghpRH+UwNmL/T1eDqp/1UpuqaHUO9v6n3\n57nkVRMTWOEBWPSB+4OixSAXe8Gun57tyt/p7ll4Xb8N1KhyjQT3v5Ky3pe1XZZsoKnPdqpXduSF\nRM4A/oCXRHzOHVTq3MleeWpF16ztYqPCue301vzfp0uYujKH/q2Tgx2SOZnU9xnx3+3yI5du7vMr\n9+/yL2HDj9Cwk5uf7eBe98O+e4MbKJCa4WpR7Ya544uLXI3pUL5rJtu2FEa85M4FNxBixZewdYkb\n0db1UshZ4fqd1k9z/UbTxriaiu+ou7pJrpYYXtc9jHooH1Z+442GO+D6kOqlur6rXetcgqyf5hLW\n/lyXcPbnumRVN8HFhbgEFFHXNSGmnea+V3ERFBa46YHCIqBhZ9i9DnKWQ6Mu7vvWqe+WcNif6+5J\nyQO6ia1c7WvTXPf5cSk/jQgs2OWaRvdtd/E36e5qv+Dux4E8F1dJH1nJ9z5UAIf2ucEb4XVgz2Y3\nAANxz24VF7n9V318ZPIMgEDWSMJwne1DcD/2s4DLVXWxzzHdgfdwNZeVPuUJuA72ks+Yg+ts31lG\nZ/tTqvp5ebHUthoJwIHCIk5/7Dsiw0N444beNK5XJ9ghGRM8G2bAV793P5in3uGSxI5VsPQTV0MB\nN0ouNNz7IW7pEtumee6ZpXpN3WwJUfVc3xLirhVR19WI8rJd8kls7ZLE/lyXtLIyXYKKrAcHct3n\nSKjXpHiw6t8rqQ3USXAJLjrZDbhY/733OSEuAUXGukSQ1NZ9t71b3XeIinPfee8WVxtp0g3yd7lk\ntHu9S67hdd26RPXK7AGoUJU720VkGzAOV/u41HuPt32JqlY4y6CIDAPG4Ib/jlXVR0TkISBTVceL\nyDdAZ2Czd8qGktFgInId8Huv/BFVfdkrz+Cn4b9f4IYm1/rhv2X5fuV2rhw7g/CQEN6+qQ/dm9kT\n2sYcQdUllLAoV/Pw98iz4mL3V31EjHuuaNc6VxuoE++m/jmwxyWDg3tdX9Wayd4ouQbuRzyqnpeQ\nZrkaT+uz3I/89pWuVtKh1OBXVTfqLyoOEJfogsgfieTq8k4sea6jNqitiQQgc91Orh47k27N4q2/\nxBhTrarcR1KbEsWJLCMtgduHtObRL5axatseWjWIrfgkY4ypRjYHQy0womcqYSHCC1MCsMa7McZU\nkSWSWiApJpJrTk3j7cyNvPS9JRNjTM1SmaV2TQ1w/7D2ZO0q4P8+XUJewSHuOrNNsEMyxhigEolE\nRJKBG4E03+NV9brAhWVKCw0RnhjZjfs/WMgTE1fSLKEuv+yZWvGJxhgTYJWpkXwMTAW+AYoCG44p\nT2RYKI9e1IWsXQX85t35LNuSx++GtiM81FoojTHBU5lEUldV7w14JKZSIsJCeP363jz82RJemLqW\n+RtzeWZUD5JiauCUDsaYk0Jl/pT91Huw0NQQEWEhPDS8E2Mu7caC7N1c+/IscvYcqPhEY4wJgMok\nkjtxyWS/iOzxXnmBDsxU7ILuKTxzRQ+Wb9nDGY9/x9+/XMbOfX6YtsEYY45BhYlEVWNVNURVo7z3\nsaoaVx3BmYqd3q4hn9/Zn04pcTw7eTW3vjGHQ0XFFZ9ojDF+UqleWhE5X0Qe817lTtluql+rBjG8\ncUMfHru4Kz+u2cFv3plPRQuWGWOMv1Rm+O+jwCnAG17RnSLST1XvD2hk5piN6JnK1rz9/POr5cRG\nhXHL4FakxNuswcaYwKrMqK1hQDdVt5aniLwKzAUskdRANw9syabdBYybtZF3M7O4+6w23DSgBWLr\ncRtjAqSyDyD4rvda76hHmaALCREeubAzU343mCHtG/DoF8u47/2F1m9ijAmYytRI/gbMFZFJuLVI\nBgD3BTQqU2Up8XV45ooePD5hBU99u4rNeft5+vLuxEaFBzs0Y8wJpjKjtt4C+gAfAO8DfVX17UAH\nZqpORPjNWW35+y87M23Vdi55bjrLttjIbWOMfx01kYhIO+/fHkBjIMt7NfHKTC1x6SnNGHvNKWTt\nzGfomKnc+94CioptVJcxxj8gm6KBAAAgAElEQVTKa9q6GxgN/KuMfQqcHpCITEAMbJPM1HsH8/Sk\nVbwwdS17DxTy6C87W1OXMabKylshcbT39hxV3e+7T0SiAhqVCYj4uhH84dwOJMZE8s+vlrMwO5cn\nR3anW9P4ik82xpijqMyorR8qWfYzIjJURJaLyCoR+VkHvYgMEJE5IlIoIiN8ygeLyDyf134RucDb\n94qIrPXZ160ysZif/GpgS94e3YfComJGPPsDT09axf5DNrGzMeb4lNdH0khEegJ1RKS7iPTwXoOA\nuhVdWERCgaeBc4AOwEgR6VDqsA3ANcCbvoWqOklVu6lqN1wTWj7wtc8h95TsV9V5FX5L8zMZaQl8\ncecAhnZqxD+/Ws7ZY6awJXd/xScaY0wp5fWRnI37kU8FHvcp3wP8vhLX7gWsUtU1ACIyDhgOLCk5\nQFXXefvKe8hhBPCFquZX4jPNMahXN5ynRnbn4oym3PrGHM55YgrndG7MH89tT90IWzzTGFM5R62R\nqOqrqjoYuEZVB/u8zlfVDypx7RRgo892lld2rC4D3ipV9oiILBCRf4tImQtxiMhoEckUkcycnJzj\n+NiTg4gwsE0y40b3IT0pmjdnbOD2N+fatPTGmEqrzHMk74vIuSLyOxH5c8mrOoITkcZAZ+Arn+L7\ngXa4+b8SgDIX3VLV51U1Q1UzkpOTAx5rbdcppR4f3NKPB8/vyNSV2zn9scmM+WYFK7fusaHCxphy\nVZhIROS/wKXA7bgn2y8Gmlfi2tlAU5/tVK/sWFwCfKiqh0oKVHWzOgeAl3FNaMZPrj41jS9/3Z9T\nWyUy5puVnPnvKVzx4nT2HSgMdmjGmBqqMqO2TlXVq4Bdqvog0BdoU4nzZgGtRSRdRCJwTVTjjzG+\nkZRq1vJqKYibhfACYNExXtNUoEVyDM9dmcHbo/tw04AWzFy7k18++wMvTl1DbsGhii9gjDmpVCaR\nFHj/5otIE+AQ7kn3cqlqIXAbrllqKfCOqi4WkYdE5HwAETlFRLJwtZznRGRxyfkikoar0XxX6tJv\niMhCYCGQBDxcie9gjkPvFoncP6w9/xjRlYNFxTz82VJO+/u3PPbVcjLX7bQ1T4wxAEhFPwYi8ifg\nKWAIbjivAi+q6p8CH55/ZGRkaGZmZrDDqPUWZefy1Lcr+XrJVlTh3C6NueuMNrRqEBPs0IwxASAi\ns1U1o8LjjuWvSm+EVJSq5lYluOpmicS/tuTu59Uf1/Hi1DWICGe2b8jVp6bRKz0h2KEZY/yosomk\nMp3tt4pIPIDXwR0iIrf4IUZTSzWqF8W9Q9vxw31DGN61CTPW7uSKF6czbdX2YIdmjAmCyjRtzfOe\nMPctm6uq3QMamR9ZjSSwducf5MJnfmDt9n1kNK/P/cPa0bO51U6Mqe38ViMBQsVnnVZv6pOIqgRn\nTizxdSP49PbT+MOw9mzO3c/IF2ZY7cSYk0hlEsmXwNsiMkREhuCG434Z2LBMbRMdGcaNA1rw6e2n\n0SIpmutfncULU9bYZJDGnAQqk0juBSYBN3uvicDvAhmUqb3qR0fw+g296Z2eyCOfL+WMx79j/PxN\nNlTYmBPYMY3aqq2sjyQ4vl+5nb9+vpQlm/PolZbAWR0bMqpPc6LCQ4MdmjGmEqo8/FdE3lHVS7yH\n/352kKp2qXqY1cMSSfAUFSuPT1jOR3M3kb27gLAQoUOTOO4d2o5+rZKCHZ4xphz+SCRNVHWTiJQ5\nr5aqrq9ijNXGEknN8O2yrXw0dxPzNu5mw858fj+sHaMHtAx2WMaYo/BHIpmjqj1E5H+qeqXfI6xG\nlkhqlv2HivjNu/P5bMFm2jWKZWDbZO46o401eRlTw1Q2kZS3elGEiFwOnCoiF5XeWck1SYz5majw\nUJ66rDttGsQybdV2nvtuDcu37OF3Z7ejfeNYfEabG2NqgfJqJKcBV+Cmci89a6+q6nUBjs1vrEZS\ns70+fT0PfrKYQ0XKJRmp/PastjSIiwp2WMac9Pw215aIXK+qL/ktsiCwRFLzbdyZz8vT1jF22lrC\nQoTLejXlN2e2pX60PftqTLD4o4/kdFX9tqxmLahdTVuWSGqPtdv38dL3a3hr5kYiw0I4t3NjLjml\nKRnN61uTlzHVzB99JAOBb4HzytinQK1JJKb2SE+K5uELOnNV3zRemrqWTxds4t3ZWaQnRTOgdRI3\nD2pFo3rW7GVMTWIPJJoabd+BQr5YtIX3Z2cxa91OoiPD+NXAltw8yIYNGxNo/uwjuRO3Nvoe4AWg\nB3Cfqn7tj0CrgyWSE8PSzXk8+Mlipq/ZSb9WifRsVp+RvZvRuF6dYIdmzAnJn7P/XqeqecBZQCJw\nJfBoFeMz5pi1bxzH69f35qYBLcjZc4D/TFpF/79P4o0ZtebZWGNOSOX1kZQo6eEcBrzmrbtuvZ4m\nKMJCQ7h/WHvuH9aejTvz+dPHi/jDh4uYsiKHM9o35LTWSVZDMaaaVaZGMltEvsYlkq9EJBYorszF\nRWSoiCwXkVUicl8Z+weIyBwRKRSREaX2FYnIPO813qc8XURmeNd8W0RsfOhJqmlCXZ6/MoNbB7dk\n9vpd3PPeAvr+7VuGPz2N6Wt2BDs8Y04alekjCQG6AWtUdbeIJACpqrqggvNCgRXAmUAWMAsYqapL\nfI5JA+KA3wLjVfU9n317VTWmjOu+A3ygquNE5L/AfFV9trxYrI/kxFdcrCzfuocpK3J47cf1ZO8u\nYHi3Jtw2uBWtG8YGOzxjaiV/9pH0BZZ7SWQU8EcgtxLn9QJWqeoaVT0IjAOG+x6gquu8hFTZGo4A\npwMlCedV4ILKnGtObCEhQvvGcdw0sCXf3D2Qmwe1ZMKSrZz75Pfc8sZstuTuD3aIxpywKpNIngXy\nRaQr8BtgNfBaJc5LATb6bGd5ZZUVJSKZIjJdREqSRSKwW1ULK7qmiIz2zs/Myck5ho81tV2diFDu\nHdqO7+4ZzC97pjBpWQ6n/2syl78wnc8XbrZFtozxs8okkkJ1/88bDvxHVZ8GqqOtoLlXpbocGCMi\nx/TggKo+r6oZqpqRnJwcmAhNjZYcG8nfLurCZ3ecxvldm5C9u4Bb3pjDxf/9kbkbdgU7PGNOGJUZ\ntbVHRO4HRgEDvD6T8Eqclw009dlO9coqRVWzvX/XiMhkoDvwPhAvImFereSYrmlOTi2SY3j0l10o\nLCrm3dlZ/OvrFVz4zA9cdkpTLuvVjK6p9Wz6FWOqoDI1kkuBA8D1qroF9+P9z0qcNwto7Y2yigAu\n4+ezCJdJROqLSKT3PgnoByzxakaTgJIRXlcDH1fmmsaEhYYwslczJt8ziNEDWvDu7CwueHoa93+w\nkAOFRcEOz5haK6BTpIjIMGAMEAqMVdVHROQhIFNVx4vIKcCHQH1gP7BFVTuKyKnAc7hO+BBgTMkM\nxCLSAtdxnwDMBUap6oHy4rBRW6Ysa7fv46lvV/LBnGwaxEYyvFsTLuqRSnpStC2yZQz+nSKlD/AU\n0B6IwCWFvapazx+BVgdLJOZoVJUpK7fz8rS1TFu1nUNFSlxUGFefmsY1p6aRGBMZ7BCNCRp/JpJM\nXLPUu0AGcBXQRlXv90eg1cESiamM9Tv2MXl5Dj+s3s7XS7YSGRbCbYNbccugVoSEWB+KOfn4NZGo\naoaILFDVLl7ZXFXt7qdYA84SiTlWq7bt5fEJy/l84RY6NI7jzjNac1aHhtYpb04q/nwgMd/rLJ8n\nIv8QkbsqeZ4xtVarBjE8fXkPxlzajYJDRdz0v9mc++T3fLV4iz2HYkwplamRNAe24Yb83gXUA55R\n1VWBD88/rEZiqqKwqJjx8zfx5MSVrNuRT2iI0LNZfW4Z3JKBbZKtlmJOWH5r2joRWCIx/lBYVMxn\nCzezMCuXLxdvIWtXAS2SoxnUpgHXnJpGs8S6wQ7RGL/yx5rtC3FL6pappL+kNrBEYvztQGER72Zm\nMWHJVn5cvYMiVU5tmcjANsm0bBBDr7QEoiMr87yvMTWXPxJJ8/JOVNVas5qQJRITSFvz9vPytHVM\nWLKF1Tn7AEiKcc+l3Du0HRFh1qVoaid/JJJWQENVnVaqvB/uwcHVfom0GlgiMdUla1c+izfl8dbM\nDUxenkNoiDC4bTID2iRzcc+m1ImwBx1N7eGPRPIpcL+qLixV3hn4q6qe55dIq4ElEhMME5duZfLy\nHL5bkcOGnfkkxURw2SnNuKKPrTNvagd/JJJZqnrKUfYtVNXOVYyx2lgiMcE2Y80Onp+yhknLtxEW\nEsL9w9pxZZ/mhIVas5epuSqbSMrrDYwvZ5/9OWXMMejdIpHeLRLZuDOfv4xfzIOfLOGJiSu5c0hr\nru2XHuzwjKmS8v4cyhSRG0sXisgNwOzAhWTMiatpQl1euCqDZ6/oQeeUejz4yRKueXkm78zayKGi\nSi0UakyNU17TVkPczLwH+SlxZOAmbrzQm1K+VrCmLVMTHSoq5ulJq3g3M4vs3QXUrxvOOZ0bM7BN\nMp1T6tEk3ir+Jrj8OdfWYKCTt7lYVb/1Q3zVyhKJqclUlckrcvhwTjYTlmyl4JBbG6V/6yTO6dSY\nYZ0bEV83IshRmpORPdnuwxKJqS0KDhaxdEse01Zu5/UZ69mad4DYyDCGtG/AoLYN6NgkjtYNq2Ol\na2MskRzBEompjVSVxZvyePa71fywaju78g8B0CW1Hmd3bMTVp6YRY0/PmwCyROLDEomp7Q4VFTNr\n3U6Wbd7DB3OzWJSdR0p8HR65sBOD2jYIdnjmBGWJxIclEnOimb1+J797bwGrc/Yxqk8z/nhuB1se\n2PidP9cjqUoQQ0VkuYisEpH7ytg/QETmiEihiIzwKe8mIj+KyGIRWSAil/rse0VE1orIPO/VLZDf\nwZiaqGfzBD6/sz839k/n9ekbGPbkVCYs2WprpZigCFgiEZFQ4GngHKADMFJEOpQ6bANwDfBmqfJ8\n4CpV7QgMBcaIiO8DkveoajfvNS8gX8CYGi4yLJQ/nNuBV651E1Dc+Fomlz4/nakrcygutoRiqk8g\ne+p6AatUdQ2AiIwDhgNLSg5Q1XXeviOexFLVFT7vN4nINiAZ2B3AeI2plQa1bUC/VkmMm7WRJ75Z\nwZUvzaR3egI39G/BGe0b2MJbJuAC2bSVAmz02c7yyo6JiPTCPQTpO9vwI16T179FJLJqYRpT+4WH\nhnBln+Z8f+/p/N/wjqzatpcbX8vkpv/NZurKHIqshmICqEaPHRSRxsD/gKtVtaTWcj+wBZdcngfu\nBR4q49zRwGiAZs2aVUu8xgRbVHgoV/ZNY2SvZrz4/Vr+PWEFXy/ZSmiI0K5RLL3TE7moRwqdUuoF\nO1RzAglkIskGmvpsp3pllSIiccBnwB9UdXpJuapu9t4eEJGXgd+Wdb6qPo9LNGRkZNifY+akEhYa\nwq8GtuSqvs2ZvDyHBVm5zN+4mzdmrGfstLWkJdbl7E6NuHVwK+KiwoMdrqnlAplIZgGtRSQdl0Au\nAy6vzIkiEoGb5+s1VX2v1L7GqrpZXMPvBcAi/4ZtzImjbkQYwzo3ZljnxgDk7T/Eq9PWMT9rN89P\nWcP7s7O575x2nNG+gU3DYo5bQJ8jEZFhwBggFBirqo+IyENApqqOF5FTcAmjPrAft/JiRxEZBbwM\nLPa53DWqOk9EvsV1vAswD/iVqu4tLw57jsSYn1uQtZs/fLiIhdm5AKQnRdMltR6XntKUU1smBTk6\nUxPYA4k+LJEYU7aiYiVz3U5mrdvJwuxcZq3bxc59BzmrQ0Nu6N+CU9Lq26ivk5g/FrYyxpzgQkPk\n8KJb4CaNfHbyKl6bvp6vl2ylS2o9bhnUkrM6NCIkxBKKKZvVSIwxP1NwsIj352Tx0vdrWbt9HxnN\n6/Pn8zrQJbW8hVPNiaZGTJFijKmd6kSEMqpPc765eyD/+GUXFmbncv5/pjH2+7UU2kqOphSrkRhj\nKrQtbz+3vTmXmet20iI5mst7NWNI+4akJ0UHOzQTQNbZ7sMSiTFVt/9QEV8u2sJzU9awdHMeAC2T\no7mmXzpndWhIw7ioIEdo/M0SiQ9LJMb418ad+UxcupV3Z2exeFMedcJDuWNIa67s29wW2zqBWCLx\nYYnEmMAoLlaWbM7jiYkrmbBkK9ERoZzfLYW+LRMZ1qkRYaHWDVubWSLxYYnEmMCbs2EXb0zfwCcL\nNnGwsJjYqDB6pydyZd/mdE2tZ0/O10KWSHxYIjGm+hwsLObbZVuZvDyHCUu2smPfQSLDQrg4I5Xr\nT2thHfS1iCUSH5ZIjAmO3PxD/LhmB5OWbePDudkcKi6mc0o9bj+9NWd2aBjs8EwFLJH4sERiTPBt\n27OfN2ds4JP5m1ids48z2jegfeM4WiRHk54UQ/vGsUSG2brzNYklEh+WSIypOQ4UFvH4hBV8uWgL\nG3fmU7LmVmiIkBJfhzM7NOSK3s1okRwT3ECNJRJflkiMqZkOFhazYWc+q7btYVF2Hsu27OG7Fdso\nVvj1kNac26Ux6UnRNnFkkFgi8WGJxJjaI2fPAe7/YCHfLN0KQPPEuvxqYEt6NKtPs4S61Imw5q/q\nYonEhyUSY2qfNTl7mb5mJ09PWkX27gIAIsNCGNgmmXO7NGZI+4b28GOA2TTyxpharUVyDC2SYxjR\nM5UNO/exMDuX+Rtz+WLRZr5espXIsBAGt23gJZUG1I2wn7NgsRqJMaZWKS5WZm/YxWcLNvPZws3k\n7DlAnfBQ+rVKpEVyDKe1SqJXegJR4dYEVlXWtOXDEokxJ6aiYmXm2p18umATP67ZQdbOAg4WFRMZ\nFkKfFolcf1o6/VsnWWf9cbKmLWPMCS80ROjbMpG+LX9a4XH62h1MWZHD14u3ctXYmSTFRNCjWX3O\n6dyIX3RpQrjN/+V3Aa2RiMhQ4AkgFHhRVR8ttX8AMAboAlymqu/57Lsa+KO3+bCqvuqV9wReAeoA\nnwN3agVfwmokxpx8Cg4W8cHcLH5YtYN5G3eTvbuA1Pp1GNQ2mfO7ptArPSHYIdZ4QW/aEpFQYAVw\nJpAFzAJGquoSn2PSgDjgt8D4kkQiIglAJpABKDAb6Kmqu0RkJnAHMAOXSJ5U1S/Ki8USiTEnN1Xl\n22XbeHbyapZsziP/YBFpiXUZ1LYB15+WTtOEusEOsUaqCU1bvYBVqrrGC2gcMBw4nEhUdZ23r/Ta\nnWcDE1R1p7d/AjBURCYDcao63St/DbgAKDeRGGNObiLCkPYNGdK+IQUHi3h39ka+W57DmzM28MoP\n62jbMJbh3ZswqE0D2jSMsenvj1EgE0kKsNFnOwvoXYVzU7xXVhnlxhhTKXUiQrmqbxpX9U0je3cB\nH8/LZtKybfzjy+X848vlhIUI3ZvF069VEqe1SqJr03jrV6nACdvZLiKjgdEAzZo1C3I0xpiaKCW+\nDrcMasUtg1qRvbuAmWt3sGzzHqav2cETE1cy5puVRISF0CIpmoFtk7l1cCviosKDHXaNE8hEkg00\n9dlO9coqe+6gUudO9spTK3NNVX0eeB5cH0klP9cYc5JKia/Dhd1Tobvb3p1/kOlrdjB3w26WbM7j\nhSlreDczi74tE2kUF0XL5Bh6pdenZXLMST+8OJCJZBbQWkTScT/2lwGXV/Lcr4C/ikh9b/ss4H5V\n3SkieSLSB9fZfhXwlJ/jNsYY4utGMLRTY4Z2agzAgqzdPDNpNUs25TFx6Vb2H3Jdu6n163DnkNYM\n75ZCRNjJ2QQW6OG/w3DDe0OBsar6iIg8BGSq6ngROQX4EKgP7Ae2qGpH79zrgN97l3pEVV/2yjP4\nafjvF8DtNvzXGFOdVJV1O/KZtXYnr89Yz4KsXOLrhnNOp8ac37UJvdITCA2p/bWUoA//rUkskRhj\nAkVVmbw8h4/mZTNhyVbyDxbRMC6SX3RpwgXdUuicWi/YIR43SyQ+LJEYY6pD/sFCJi7dxvj5m/hu\neQ4Hi4oZ2CaZHs3q0yW1HgPaJNeqmkpNeI7EGGNOKnUjwjivaxPO69qE3PxDvPzDWj6cm82UlTmo\nQnio0KheFGmJ0TRLqEuv9AT6t04mIToi2KFXidVIjDEmwPIPFjJlRQ5zN+xmU+5+1u/Yx7rt+8jb\nXwhA/brhDGnfkIt7ptIrPaHGjAKzpi0flkiMMTVNcbEyd+Nu5qzfxdLNeXy1eAv7DhbRtWk8I3qk\n0L91Ms0T6wY1qVjTljHG1GAhIULP5vXp2dw95ZB/sJCP523iv9+t5k8fLwagaUId+rdOZkDrJAa1\nbVBj11ixGokxxtQgqsr6HflMXZnDlJXb+XH1DvYeKCS+bjinedO2DO+WUi1r11vTlg9LJMaY2upQ\nUTEz1uzkzZnrmb1+F1vzDhBfN5xLT2lK3xaJhIjQOaUe9QPQYW+JxIclEmPMiUDVrQj5yg/r+Grx\nFoq9n28ROKN9Q/q0SKRraj06p9YjMqzqNRbrIzHGmBOMiNC7RSK9WySSs+cAK7buAWDKihw+nreJ\nCUu2Hj42NjKMjilx/PXCzrRIjgloXJZIjDGmFkqOjSQ5NhKAfq2SuH9YezbtLmBRdi5LNuexY+9B\n5mzYRWJ0ZMBjsURijDEniCbxdWgSX4ezOjaq1s89OaeqNMYY4zeWSIwxxlSJJRJjjDFVYonEGGNM\nlVgiMcYYUyWWSIwxxlSJJRJjjDFVYonEGGNMlZwUc22JSA6w/jhOTQK2+zmcE43do4rZPSqf3Z+K\nBeseNVfV5IoOOikSyfESkczKTFh2MrN7VDG7R+Wz+1Oxmn6PrGnLGGNMlVgiMcYYUyWWSMr3fLAD\nqAXsHlXM7lH57P5UrEbfI+sjMcYYUyVWIzHGGFMllkiOQkSGishyEVklIvcFO55gEZGxIrJNRBb5\nlCWIyAQRWen9W98rFxF50rtnC0SkR/Airx4i0lREJonIEhFZLCJ3euV2jzwiEiUiM0VkvnePHvTK\n00Vkhncv3haRCK880tte5e1PC2b81UVEQkVkroh86m3XmvtjiaQMIhIKPA2cA3QARopIh+BGFTSv\nAENLld0HTFTV1sBEbxvc/WrtvUYDz1ZTjMFUCPxGVTsAfYBbvf+t2D36yQHgdFXtCnQDhopIH+Dv\nwL9VtRWwC7jeO/56YJdX/m/vuJPBncBSn+1ac38skZStF7BKVdeo6kFgHDA8yDEFhapOAXaWKh4O\nvOq9fxW4wKf8NXWmA/Ei0rh6Ig0OVd2sqnO893twPwQp2D06zPuue73NcO+lwOnAe1556XtUcu/e\nA4aIiFRTuEEhIqnAucCL3rZQi+6PJZKypQAbfbazvDLjNFTVzd77LUBD7/1Jfd+8JobuwAzsHh3B\na7aZB2wDJgCrgd2qWugd4nsfDt8jb38ukFi9EVe7McDvgGJvO5FadH8skZgqUTfs76Qf+iciMcD7\nwK9VNc93n90jUNUiVe0GpOJq/O2CHFKNISK/ALap6uxgx3K8LJGULRto6rOd6pUZZ2tJc4z37zav\n/KS8byISjksib6jqB16x3aMyqOpuYBLQF9esF+bt8r0Ph++Rt78esKOaQ61O/YDzRWQdrhn9dOAJ\natH9sURStllAa2/URARwGTA+yDHVJOOBq733VwMf+5Rf5Y1M6gPk+jTvnJC8tumXgKWq+rjPLrtH\nHhFJFpF4730d4ExcX9IkYIR3WOl7VHLvRgDf6gn8wJuq3q+qqaqahvut+VZVr6A23R9VtVcZL2AY\nsALXlvuHYMcTxPvwFrAZOIRrp70e1x47EVgJfAMkeMcKbrTbamAhkBHs+Kvh/pyGa7ZaAMzzXsPs\nHh1xj7oAc717tAj4s1feApgJrALeBSK98ihve5W3v0Wwv0M13qtBwKe17f7Yk+3GGGOqxJq2jDHG\nVIklEmOMMVViicQYY0yVWCIxxhhTJZZIjDHGVIklEmOMMVViicQcNxFREXndZztMRHJKpsE+huus\nE5Gk4zlGRGJE5DkRWS0is0Vksoj0PpbPP8ZY03yn1D/GczNE5Env/SAROfU4rvFrEbnqeD7/GD/n\n96W2f/DTdY/rex/lWski8qU/rmWqxhKJqYp9QCfvaWVwTyxX93QfL+JmJ26tqj2Ba4Fyk1KwqGqm\nqt7hbQ4CjukH1ZsO4zrgTT+HVpYjEomq+uXHn+P/3j+jqjnAZhHp54e4TBVYIjFV9Tlu+muAkbgn\n4YHDizt95C3gNF1EunjliSLytbfI0Yu4p71LzhnlLYI0z6tphB7tg0WkJdAb+KOqFgOo6lpV/czb\nf7eILPJev/bK0kRkmYi8IiIrROQNETlDRKaJW4Sql3fcAyLyPxH50Su/sYzPDxWRf4rILO873uSV\nXygiE71pUBp7n9PI+2v8U2+W4F8Bd3nfs7+IrPXm7EJE4ny3fZwOzFFvRliv9vV3736tEJH+5dyr\no8XaWESmeHEs8mJ5FKjjlb3hHbfX+3eQiHwnIh+LyBoReVRErvBiWOj9N0FEzhO36NJcEflGRBoe\n5Xunici3XkwTRaSZd/4rIvJfEZkB/ENEBnrnzPOuGet9tY+AK472vU01Cfaj9faqvS9gL276i/dw\n0zbM48gpHp4C/uK9Px2Y571/kp+myTgXN8VIEtAe+AQI9/Y9A1zlvV8HJJX6/POBD48SW0/cFCTR\nQAywGDfFexpuMarOuD+kZgNjcclsOPCRd/4DwHygjhfbRqCJd/4i75jRuCQGEAlkAune9uvAbcCn\nwEivzPfePAD81ifel4ELfK77rzK+04PA7T7bk0uOw03L8k05/63KjBX4Dd4UQEAoEFvy37b0f2uf\n77AbaOxdJxt40Nt3JzDGe18fDs+ccYNPnKW/9yfA1d7763zu/yvevQv1Oa6f9z4GCPPepwALg/3/\nhZP9VWaV0ZjKUtUF3l+aI3G1E1+nAb/0jvvWq4nEAQOAi7zyz0Rkl3f8EFwCmCVunZ46/DRr7rE6\nDZdk9gGIyAdAf9yEd2tVdaFXvhi3kqGKyEJcoijxsaoWAAUiMgk3/fk8n/1nAV1EpGRivXq4lQ/X\nArfj5pWarqpvUbEXcXiq79QAAANESURBVOtRfIRrnvtZDQj34720VFnJbMOzS8Ve2tFinQWM9Wo/\nH6nqvKNd4P/bO4MQm8Iojv/+lGSSImzULGjKSrGymcZKshijKaUkNRsLJQshi5lshjQLVpgGIwtN\nUSQZO4xkQmYyo5CSFE1ZSJI4Fud7zXW7783Me8OTOb/V98533/ed79737rnnnNt3Mgxb2mhS0mtg\nMMlHgU2pvQq4It/5eAF+TorYSPotAJeAE5m+ATP7kdpDQE/ykK6a2bsk/4gb+KCOhCEJZoPrwEn8\nabWWAjsCLprZ4Wke/xxYJ2l+5oYzHb5l2j8zn3/y+38ivxFd/rNwD+F2wRyr0ngrJc2zFHorh5kN\npTBPC/4UXpTQ/4p7fllKuv+g8v+5rK6SmnHP8IKkHjPrr6Qr0zt/p4EeM7ue1tQ5xZhFfCk1zKxb\n0k3c8xqStNnMXuDn42sVYwezSORIgtmgDw9vjObk90jx63QzmTAv+nQX2JnkW/AwCPhuue2SVqS+\npZIay01qZq/xEE2XkguTbsZb09zbJC2S1AC0JdlMaJW0UNIy3EgO5/pvA3szuY0mSQ3y5HAf7qWN\nAwcKxv4MLM7J+vFE+vky+owDa2a4hql0bQQ+mNk53Ctan47/XpCjmQlLmHzxYndGnl/3A3zrdPDf\nSuE1krTazEbN7Dh+HUqFsZpwzy+oI2FIgpoxs3dmdqqgqxPYIGkE6GbyhtIFNKew0nbgbRpnDDgK\nDKbv3MHDOZXowMvYvpK/lnsBrzb3JLUf4aVve83s6QyXNoLXhHgIHDOz97n+XmAMeJLmPoM/kR8B\n7pnZfdyIdEham/vuDaCtlHROssu4US0XCruFhwWroZyuLcAzSU+BHXhBJYCzwEgp2V4FncCApMfA\nREaeX/c+YE+63rvwPEsR+9PLACN4SYNbSb4JuFmljsEsEdvIB0EBkjrxBPPJvzhnO9BqZrsqHHMN\nOGhmL/+WXv8yku7i5+zTlAcHf4zIkQTBP4Ck08AWPAdQiUO4lzbnDYmk5XgeJoxInQmPJAj+IyRt\nBo7nxG/MrK0e+gRzgzAkQRAEQU1Esj0IgiCoiTAkQRAEQU2EIQmCIAhqIgxJEARBUBNhSIIgCIKa\n+AXXAwYZPivfJQAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZF7-ml6BhRRf",
        "colab_type": "text"
      },
      "source": [
        "## Try adjusting these hyperparameters\n",
        "\n",
        "#### Random Forest\n",
        "- class_weight (for imbalanced classes)\n",
        "- max_depth (usually high, can try decreasing)\n",
        "- n_estimators (too low underfits, too high wastes time)\n",
        "- min_samples_leaf (increase if overfitting)\n",
        "- max_features (decrease for more diverse trees)\n",
        "\n",
        "#### Xgboost\n",
        "- scale_pos_weight (for imbalanced classes)\n",
        "- max_depth (usually low, can try increasing)\n",
        "- n_estimators (too low underfits, too high wastes time/overfits) — Use Early Stopping!\n",
        "- learning_rate (too low underfits, too high overfits)\n",
        "\n",
        "For more ideas, see [Notes on Parameter Tuning](https://xgboost.readthedocs.io/en/latest/tutorials/param_tuning.html) and [DART booster](https://xgboost.readthedocs.io/en/latest/tutorials/dart.html)."
      ]
    }
  ]
}